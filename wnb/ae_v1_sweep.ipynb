{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9967f2f3-101e-427e-ab45-4f5c1978ab06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb and pytorch manual \n",
    "# https://colab.research.google.com/drive/1XDtq-KT0GkX06a_g1MevuLFOMk4TxjKZ#scrollTo=bZpt5W2NNl6S\n",
    "\n",
    "# for hyperparameter sweeping\n",
    "# https://colab.research.google.com/github/wandb/examples/blob/master/colabs/pytorch/Organizing_Hyperparameter_Sweeps_in_PyTorch_with_W%26B.ipynb#scrollTo=W_YSZCkITmVJ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be15c793-b481-4c47-a09d-db027f5462c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import argparse\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# from torchvision import datasets, transforms\n",
    "\n",
    "import logging\n",
    "logging.propagate = False\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "from datetime import datetime\n",
    "import wandb\n",
    "\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8aa83412-5353-4dd9-9964-3f5043a65aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbeomgon-yu\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "!wandb login"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745d1b2d-9553-4d9f-81f1-47395b9f7851",
   "metadata": {},
   "source": [
    "## hyperparameter sweep using wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "889b0d6a-7e82-4707-bde5-e43dee473aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use random search\n",
    "sweep_config = {\n",
    "    'method': 'random'\n",
    "    }\n",
    "\n",
    "# for bayesian search, this value should be included\n",
    "metric = {\n",
    "    'name': 'f1_score',\n",
    "    'goal': 'maximize'   \n",
    "    }\n",
    "\n",
    "sweep_config['metric'] = metric    \n",
    "\n",
    "parameters_dict = {\n",
    "    'optimizer': {\n",
    "        'values': ['adam', 'sgd']\n",
    "        # 'values': ['adam']\n",
    "        },\n",
    "    }\n",
    "\n",
    "parameters_dict.update({\n",
    "    'epochs': {\n",
    "        'value': 100}\n",
    "    })\n",
    "\n",
    "sweep_config['parameters'] = parameters_dict\n",
    "\n",
    "parameters_dict.update({\n",
    "    'lr': {\n",
    "        # a q_log_uniform_values distribution between 0 and 0.1\n",
    "        'distribution': 'q_log_uniform_values',\n",
    "        'q': 1e-5,\n",
    "        'min': 1e-4,\n",
    "        'max': 5e-2\n",
    "      },\n",
    "    'batch_size': {\n",
    "        'values': [128,256,512,1024]\n",
    "      },\n",
    "    'svd_reduction': {\n",
    "        'values': [True, False]\n",
    "      },    \n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b0f04c8-52d9-4190-bda7-327a804f108a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'random',\n",
      " 'metric': {'goal': 'maximize', 'name': 'f1_score'},\n",
      " 'parameters': {'batch_size': {'values': [128, 256, 512, 1024]},\n",
      "                'epochs': {'value': 100},\n",
      "                'lr': {'distribution': 'q_log_uniform_values',\n",
      "                       'max': 0.05,\n",
      "                       'min': 0.0001,\n",
      "                       'q': 1e-05},\n",
      "                'optimizer': {'values': ['adam', 'sgd']},\n",
      "                'svd_reduction': {'values': [True, False]}}}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "pprint.pprint(sweep_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f33a6316-5140-4b7b-b746-f186e91e3a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: ep2s3sgj\n",
      "Sweep URL: https://wandb.ai/beomgon-yu/Credit%20Card%20Fraud%20Detection%20Sweep/sweeps/ep2s3sgj\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"Credit Card Fraud Detection Sweep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c1d5ce-739a-4136-a323-0be4f0a1ed1a",
   "metadata": {},
   "source": [
    "# set seed for reproduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab8a1c24-0ccc-4099-947c-6b0a88cc9830",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import seed_everything"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a398fdb1-1a98-4486-818e-6180cc116a4b",
   "metadata": {},
   "source": [
    "## For SVD reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7148bda-5daa-4bd5-852f-01aa13faecb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduced_mat(df) :\n",
    "    u, s, v = np.linalg.svd(df, full_matrices=False)\n",
    "    s[0] = 0\n",
    "    rdf = pd.DataFrame( u @ np.diag(s) @ v)\n",
    "    return rdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fcfa15-01fb-4176-af2d-d5f0640bc9c1",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ae7b0a9-a019-47fc-81cd-25f3656ce240",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import CDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f87fac-80ba-408d-bcd5-daf8f705ed46",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8b22279-3e83-43ef-a6be-d5b4aab40ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import AutoEncoder, TiedAE, StackedAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5193792-9634-4435-bf49-eea18ff4afc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer() :\n",
    "    def __init__(self, model, optimizer, train_loader, val_loader, scheduler, config) :\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.scheduler = scheduler\n",
    "        self.device = config.device\n",
    "        self.epochs = config.epochs\n",
    "        self.lr = config.lr\n",
    "        \n",
    "        self.criterion = nn.L1Loss().to(self.device)\n",
    "        \n",
    "    def fit(self,) :\n",
    "        self.model.to(self.device)\n",
    "        best_score = 0\n",
    "        for epoch in range(self.epochs) :\n",
    "            self.model.train()\n",
    "            train_loss = []\n",
    "            \n",
    "            for x in iter(self.train_loader) :\n",
    "                x = x.to(self.device)\n",
    "                _x = self.model(x)\n",
    "                \n",
    "                loss = self.criterion(x, _x)\n",
    "                # loss = self.criterion(x, _x) + 0.5*self.criterion(x, x1)\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                train_loss.append(loss.item())\n",
    "                wandb.log({'train loss' : loss.item()})\n",
    "                \n",
    "            score = self.validation(self.model, 0.95)\n",
    "            wandb.log({'f1_score' : score})\n",
    "            \n",
    "            if self.scheduler is not None :\n",
    "                self.scheduler.step(score)\n",
    "\n",
    "            \n",
    "    def validation(self, eval_model, threshold) :\n",
    "        cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "        eval_model.eval()\n",
    "        pred_y = []\n",
    "        true_y = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for x, y in iter(self.val_loader) :\n",
    "                x = x.to(self.device)\n",
    "                y = y.to(self.device)\n",
    "                \n",
    "                _x = self.model(x)\n",
    "                diff = cos(x, _x).cpu().tolist()\n",
    "                batch_pred = np.where(np.array(diff) < threshold, 1, 0).tolist()\n",
    "                pred_y += batch_pred\n",
    "                true_y += y.tolist()\n",
    "\n",
    "        return f1_score(true_y, pred_y, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cab059-b166-4f48-8467-788a39b3bafb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2311f239-f77c-4fe3-9c21-9b83d1503199",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main() :\n",
    "    \n",
    "    with wandb.init(config=None) :\n",
    "        \n",
    "        config = wandb.config\n",
    "        config.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        config.num_workers = 8\n",
    "        config.seed = 42\n",
    "        config.momentum = 0.9\n",
    "        config.weight_decay = 1e-4\n",
    "        \n",
    "        seed_everything(config.seed) \n",
    "\n",
    "        train_df = pd.read_csv('../dataset/train.csv')\n",
    "        val_df = pd.read_csv('../dataset/val.csv')\n",
    "        train_df = train_df.drop(columns=['ID'])\n",
    "        val_df = val_df.drop(columns=['ID'])  \n",
    "        \n",
    "        if config.svd_reduction :\n",
    "            train_df = reduced_mat(train_df)\n",
    "            val = reduced_mat(val_df.drop(columns=['Class']))\n",
    "            val['Class'] = val_df['Class']\n",
    "            val_df = val\n",
    "\n",
    "        train_dataset = CDataset(train_df)\n",
    "        train_loader = DataLoader(train_dataset, batch_size = config.batch_size, shuffle=True, num_workers=config.num_workers)\n",
    "\n",
    "        val_dataset = CDataset(val_df, eval_mode=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size = config.batch_size, shuffle=False, num_workers=config.num_workers)    \n",
    "\n",
    "        model = AutoEncoder()\n",
    "        model.eval()\n",
    "\n",
    "        # if config.adam :\n",
    "        if config.optimizer == 'adam' :\n",
    "            optimizer = torch.optim.Adam(params=model.parameters(), lr = config.lr)\n",
    "        else :\n",
    "            optimizer = torch.optim.SGD(model.parameters(), config.lr,\n",
    "                                        momentum=config.momentum,\n",
    "                                        weight_decay=config.weight_decay)\n",
    "\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=10, threshold_mode='abs', min_lr=1e-8, verbose=True)\n",
    "        # scheduler = StepLR(optimizer, step_size=50, gamma=0.2)\n",
    "\n",
    "        wandb.watch(model, log='all')\n",
    "\n",
    "        trainer = Trainer(model, optimizer, train_loader, val_loader, scheduler, config)\n",
    "\n",
    "        wandb.save('model.h5')\n",
    "\n",
    "        trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c3d82f-01b7-499a-bb72-5ec435914623",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: m7q17neo with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.013970000000000002\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsvd_reduction: False\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbeomgon-yu\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.21 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/beomgon/dacon/fraud_detection/wnb/wandb/run-20220720_193233-m7q17neo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/beomgon-yu/Credit%20Card%20Fraud%20Detection%20Sweep/runs/m7q17neo\" target=\"_blank\">robust-sweep-1</a></strong> to <a href=\"https://wandb.ai/beomgon-yu/Credit%20Card%20Fraud%20Detection%20Sweep\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/beomgon-yu/Credit%20Card%20Fraud%20Detection%20Sweep/sweeps/ep2s3sgj\" target=\"_blank\">https://wandb.ai/beomgon-yu/Credit%20Card%20Fraud%20Detection%20Sweep/sweeps/ep2s3sgj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.agent(sweep_id, main, count=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eca0fff-9307-4b9f-b5dc-b225fc389300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ce202d-839e-4339-bf7a-ccf24453f54c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
