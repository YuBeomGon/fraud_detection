{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9967f2f3-101e-427e-ab45-4f5c1978ab06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb and pytorch manual \n",
    "# https://colab.research.google.com/drive/1XDtq-KT0GkX06a_g1MevuLFOMk4TxjKZ#scrollTo=bZpt5W2NNl6S\n",
    "\n",
    "# for hyperparameter sweeping\n",
    "# https://colab.research.google.com/github/wandb/examples/blob/master/colabs/pytorch/Organizing_Hyperparameter_Sweeps_in_PyTorch_with_W%26B.ipynb#scrollTo=W_YSZCkITmVJ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be15c793-b481-4c47-a09d-db027f5462c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import argparse\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# from torchvision import datasets, transforms\n",
    "\n",
    "import logging\n",
    "logging.propagate = False\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "from datetime import datetime\n",
    "import wandb\n",
    "\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa83412-5353-4dd9-9964-3f5043a65aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wandb login"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745d1b2d-9553-4d9f-81f1-47395b9f7851",
   "metadata": {},
   "source": [
    "## hyperparameter sweep using wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889b0d6a-7e82-4707-bde5-e43dee473aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use random search\n",
    "sweep_config = {\n",
    "    'method': 'random'\n",
    "    }\n",
    "\n",
    "# for bayesian search, this value should be included\n",
    "metric = {\n",
    "    'name': 'f1_score',\n",
    "    'goal': 'maximize'   \n",
    "    }\n",
    "\n",
    "sweep_config['metric'] = metric    \n",
    "\n",
    "parameters_dict = {\n",
    "    'optimizer': {\n",
    "        'values': ['adam', 'sgd']\n",
    "        # 'values': ['adam']\n",
    "        },\n",
    "    # 'fc_layer_size': {\n",
    "    #     'values': [128, 256, 512]\n",
    "    #     },\n",
    "    # 'dropout': {\n",
    "    #       'values': [0.3, 0.4, 0.5]\n",
    "    #     },\n",
    "    }\n",
    "\n",
    "parameters_dict.update({\n",
    "    'epochs': {\n",
    "        'value': 100}\n",
    "    })\n",
    "\n",
    "sweep_config['parameters'] = parameters_dict\n",
    "\n",
    "parameters_dict.update({\n",
    "    'lr': {\n",
    "        # a q_log_uniform_values distribution between 0 and 0.1\n",
    "        'distribution': 'q_log_uniform_values',\n",
    "        'q': 1e-5,\n",
    "        'min': 1e-4,\n",
    "        'max': 5e-2\n",
    "      },\n",
    "    'batch_size': {\n",
    "        'values': [128,256,512,1024]\n",
    "      },\n",
    "    'svd_reduction': {\n",
    "        'values': [True, False]\n",
    "      },    \n",
    "    # 'momentum': {\n",
    "    #     # float between 0.1 and 0.9\n",
    "    #     # with evenly-distributed logarithms \n",
    "    #     'distribution': 'uniform',\n",
    "    #     'min': 0.1,\n",
    "    #     'max': 0.9,\n",
    "    #   },\n",
    "    # 'weight_decay': {\n",
    "    #     # float between 1e-3 and 1e-5\n",
    "    #     # with evenly-distributed logarithms \n",
    "    #     'distribution': 'q_log_uniform_values',\n",
    "    #     'q': 10,\n",
    "    #     'min': 1e-5,\n",
    "    #     'max': 1e-3,\n",
    "    #   },    \n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0f04c8-52d9-4190-bda7-327a804f108a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "pprint.pprint(sweep_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33a6316-5140-4b7b-b746-f186e91e3a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"Credit Card Fraud Detection Sweep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc0857c-d264-4a34-8e75-9e30a381b3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# now = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "# wandb.init(project='Credit Card Fraud Detection',  name=now, mode='online')\n",
    "# wandb.watch_called = False\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# config =wandb.config\n",
    "# config.batch_size = 1024\n",
    "# config.epochs = 100\n",
    "# config.lr = 1e-2\n",
    "# config.momentum = 0.5\n",
    "# config.weight_decay = 1e-4\n",
    "# config.device = device\n",
    "# config.seed = 42\n",
    "# config.log_interval = 10\n",
    "# config.num_workers = 8\n",
    "# config.adam = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c1d5ce-739a-4136-a323-0be4f0a1ed1a",
   "metadata": {},
   "source": [
    "# set seed for reproduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2331a56b-4170-467d-a587-ae661a716086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed) :\n",
    "    random.seed(seed)\n",
    "    os.environ['PYHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a398fdb1-1a98-4486-818e-6180cc116a4b",
   "metadata": {},
   "source": [
    "## For SVD reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7148bda-5daa-4bd5-852f-01aa13faecb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduced_mat(df) :\n",
    "    u, s, v = np.linalg.svd(df, full_matrices=False)\n",
    "    s[0] = 0\n",
    "    rdf = pd.DataFrame( u @ np.diag(s) @ v)\n",
    "    return rdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fcfa15-01fb-4176-af2d-d5f0640bc9c1",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2074f8c2-ddb0-453b-9065-cfe3bc4630b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas is 18 times slower than Numpy (15.8ms vs 0.874 ms). Pandas is 20 times slower than Numpy\n",
    "# therefore Use numpy for faster data loading\n",
    "\n",
    "class CDataset(Dataset):\n",
    "    def __init__(self, df, eval_mode=False):\n",
    "        self.df = df\n",
    "        self.eval_mode = eval_mode\n",
    "        if self.eval_mode:\n",
    "            self.labels = self.df['Class'].values\n",
    "            self.df = self.df.drop(columns=['Class']).values\n",
    "        else:\n",
    "            self.df = self.df.values\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        if self.eval_mode:\n",
    "            self.x = self.df[index]\n",
    "            self.y = self.labels[index]\n",
    "            return torch.Tensor(self.x), self.y\n",
    "        else:\n",
    "            self.x = self.df[index]\n",
    "            return torch.Tensor(self.x)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97ad33d-0c21-4ea3-b21c-8921a5d0371c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = CDataset(train_df)\n",
    "# train_loader = DataLoader(train_dataset, batch_size = config.batch_size, shuffle=True, num_workers=config.num_workers)\n",
    "\n",
    "# val_dataset = CDataset(val_df, eval_mode=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size = config.batch_size, shuffle=False, num_workers=config.num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f87fac-80ba-408d-bcd5-daf8f705ed46",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ed1d6c-1f7a-4152-a4aa-21df8714f7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module) :\n",
    "    def __init__(self) :\n",
    "        super().__init__()\n",
    "        # self.act = nn.ReLU()\n",
    "        self.act = nn.GELU()\n",
    "        # self.act = nn.LeakyReLU()\n",
    "        \n",
    "        self.dim = 30\n",
    "        self.hidden1 = 64\n",
    "        self.hidden2 = 128\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.BatchNorm1d(self.dim),\n",
    "            nn.Linear(self.dim,self.hidden1),\n",
    "            nn.BatchNorm1d(self.hidden1),\n",
    "            self.act,\n",
    "            nn.Linear(self.hidden1,self.hidden2),\n",
    "            nn.BatchNorm1d(self.hidden2),\n",
    "            self.act,\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(self.hidden2,self.hidden1),\n",
    "            nn.BatchNorm1d(self.hidden1),\n",
    "            self.act,\n",
    "            nn.Linear(self.hidden1,self.dim),\n",
    "        )\n",
    "        \n",
    "#         self.encoder2 = nn.Sequential(\n",
    "#             nn.BatchNorm1d(self.dim),\n",
    "#             nn.Linear(self.dim,self.hidden1),\n",
    "#             nn.BatchNorm1d(self.hidden1),\n",
    "#             self.act,\n",
    "#             nn.Linear(self.hidden1,self.hidden2),\n",
    "#             nn.BatchNorm1d(self.hidden2),\n",
    "#             self.act,\n",
    "#         )\n",
    "        \n",
    "#         self.decoder2 = nn.Sequential(\n",
    "#             nn.Linear(self.hidden2,self.hidden1),\n",
    "#             nn.BatchNorm1d(self.hidden1),\n",
    "#             self.act,\n",
    "#             nn.Linear(self.hidden1,self.dim),\n",
    "#         )        \n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.BatchNorm1d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)          \n",
    "        \n",
    "    def forward(self, x) :\n",
    "        \n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        \n",
    "#         x = self.encoder2(x1)\n",
    "#         x = self.decoder2(x)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5193792-9634-4435-bf49-eea18ff4afc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer() :\n",
    "    def __init__(self, model, optimizer, train_loader, val_loader, scheduler, config) :\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.scheduler = scheduler\n",
    "        self.device = config.device\n",
    "        self.epochs = config.epochs\n",
    "        self.lr = config.lr\n",
    "        \n",
    "        self.criterion = nn.L1Loss().to(self.device)\n",
    "        \n",
    "    def fit(self,) :\n",
    "        self.model.to(self.device)\n",
    "        best_score = 0\n",
    "        for epoch in range(self.epochs) :\n",
    "            self.model.train()\n",
    "            train_loss = []\n",
    "            \n",
    "            for x in iter(self.train_loader) :\n",
    "                x = x.to(self.device)\n",
    "                _x = self.model(x)\n",
    "                \n",
    "                loss = self.criterion(x, _x)\n",
    "                # loss = self.criterion(x, _x) + 0.5*self.criterion(x, x1)\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                train_loss.append(loss.item())\n",
    "                wandb.log({'train loss' : loss.item()})\n",
    "                \n",
    "            score = self.validation(self.model, 0.95)\n",
    "            wandb.log({'f1_score' : score})\n",
    "            \n",
    "            if self.scheduler is not None :\n",
    "                self.scheduler.step(score)\n",
    "            \n",
    "            # print(f'epoch :[{epoch}] train loss [{np.mean(train_loss)}] val score [{score}]')\n",
    "            \n",
    "            # for param_group in self.optimizer.param_groups:\n",
    "            #     print(param_group['lr'])      \n",
    "            \n",
    "            # print(f'epoch :[{epoch}] train loss [{np.mean(train_loss)}] val score [{score}] lr [{self.scheduler.get_lr()}]')\n",
    "\n",
    "            if best_score < score :\n",
    "                best_score = score\n",
    "                \n",
    "            wandb.log({'best_score' : best_score})\n",
    "#                 torch.save(self.model.state_dict(), '../saved/best_model.pth')\n",
    "            \n",
    "    def validation(self, eval_model, threshold) :\n",
    "        cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "        eval_model.eval()\n",
    "        pred_y = []\n",
    "        true_y = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for x, y in iter(self.val_loader) :\n",
    "                x = x.to(self.device)\n",
    "                y = y.to(self.device)\n",
    "                \n",
    "                _x = self.model(x)\n",
    "                diff = cos(x, _x).cpu().tolist()\n",
    "                batch_pred = np.where(np.array(diff) < threshold, 1, 0).tolist()\n",
    "                pred_y += batch_pred\n",
    "                true_y += y.tolist()\n",
    "\n",
    "        return f1_score(true_y, pred_y, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cab059-b166-4f48-8467-788a39b3bafb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2311f239-f77c-4fe3-9c21-9b83d1503199",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main() :\n",
    "    \n",
    "    with wandb.init(config=None) :\n",
    "        \n",
    "        config = wandb.config\n",
    "        config.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        config.num_workers = 8\n",
    "        config.seed = 42\n",
    "        config.momentum = 0.9\n",
    "        config.weight_decay = 1e-4\n",
    "\n",
    "        train_df = pd.read_csv('../dataset/train.csv')\n",
    "        val_df = pd.read_csv('../dataset/val.csv')\n",
    "        train_df = train_df.drop(columns=['ID'])\n",
    "        val_df = val_df.drop(columns=['ID'])  \n",
    "        \n",
    "        if config.svd_reduction :\n",
    "            train_df = reduced_mat(train_df)\n",
    "            val = reduced_mat(val_df.drop(columns=['Class']))\n",
    "            val['Class'] = val_df['Class']\n",
    "            val_df = val\n",
    "\n",
    "        train_dataset = CDataset(train_df)\n",
    "        train_loader = DataLoader(train_dataset, batch_size = config.batch_size, shuffle=True, num_workers=config.num_workers)\n",
    "\n",
    "        val_dataset = CDataset(val_df, eval_mode=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size = config.batch_size, shuffle=False, num_workers=config.num_workers)    \n",
    "\n",
    "        seed_everything(config.seed)    \n",
    "\n",
    "        model = AutoEncoder()\n",
    "        model.eval()\n",
    "\n",
    "        # if config.adam :\n",
    "        if config.optimizer == 'adam' :\n",
    "            optimizer = torch.optim.Adam(params=model.parameters(), lr = config.lr)\n",
    "        else :\n",
    "            optimizer = torch.optim.SGD(model.parameters(), config.lr,\n",
    "                                        momentum=config.momentum,\n",
    "                                        weight_decay=config.weight_decay)\n",
    "\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=10, threshold_mode='abs', min_lr=1e-8, verbose=True)\n",
    "        # scheduler = StepLR(optimizer, step_size=50, gamma=0.2)\n",
    "\n",
    "        wandb.watch(model, log='all')\n",
    "\n",
    "        trainer = Trainer(model, optimizer, train_loader, val_loader, scheduler, config)\n",
    "\n",
    "        wandb.save('model.h5')\n",
    "\n",
    "        trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b470b61-9168-497d-927a-937b32b39e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     main(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c3d82f-01b7-499a-bb72-5ec435914623",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.agent(sweep_id, main, count=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0445e390-75b7-41ab-82f9-57f82c642832",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71105fa-3474-428e-b0fb-e96336a2a957",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eca0fff-9307-4b9f-b5dc-b225fc389300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ce202d-839e-4339-bf7a-ccf24453f54c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
