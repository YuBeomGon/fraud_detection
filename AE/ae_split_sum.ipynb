{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27beacea-6bc4-4f6d-8024-d7661d3bb946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://dacon.io/competitions/official/235930/codeshare/5508?page=1&dtype=recent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf4fe48e-c012-4895-99e0-f3e2a7d1f658",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23c88f55-39a2-4f92-a939-eefc0aa1378f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50f138e7-da83-41ad-b588-fe85c6dbef7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "lr = 1e-3\n",
    "batch_size = 512\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-4\n",
    "seed = 42\n",
    "NUM_WORKERS = 8\n",
    "saved_model = '../saved/ae_split5/best_model1.pth'\n",
    "\n",
    "param = {\n",
    "            'epochs' : epochs,\n",
    "            'lr' :lr,\n",
    "            'batch_size' : batch_size,\n",
    "            'momentum' : momentum,\n",
    "            'weight_decay' : weight_decay\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8b2a22e-d2cc-4913-beea-246cb512369e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../saved/ae_split5'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'/'.join(saved_model.split('/')[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d07f699-c8c6-4c60-b181-263b093cd2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed) :\n",
    "    random.seed(seed)\n",
    "    os.environ['PYHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# seed_everything(seed)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dc3b08e-4bf9-442b-a9e5-2d383ef2240a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(113842, 30)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('../dataset/train.csv')\n",
    "val_df = pd.read_csv('../dataset/val.csv')\n",
    "train_df = train_df.drop(columns=['ID'])\n",
    "val_df = val_df.drop(columns=['ID'])\n",
    "test_df = pd.read_csv('../dataset/test.csv')\n",
    "test_df = test_df.drop(columns=['ID'])\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de6a6b3b-1460-4a9a-9a02-18ff2efe8c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler\n",
    "col=[col for col in val_df.columns if col not in ['ID','Class']]\n",
    "\n",
    "for i in col:\n",
    "    sc=StandardScaler()\n",
    "    scaler = sc.fit(train_df[i].values.reshape(-1,1))\n",
    "    train_df[i] = scaler.transform(train_df[i].values.reshape(-1,1))\n",
    "    val_df[i] = scaler.transform(val_df[i].values.reshape(-1,1))\n",
    "    test_df[i] = scaler.transform(test_df[i].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c51032d7-d3a2-4bcd-9108-562207763da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDataset(Dataset):\n",
    "    def __init__(self, df, eval_mode=False):\n",
    "        self.df = df\n",
    "        self.eval_mode = eval_mode\n",
    "        if self.eval_mode:\n",
    "            self.labels = self.df['Class'].values\n",
    "            self.df = self.df.drop(columns=['Class']).values\n",
    "        else:\n",
    "            self.df = self.df.values\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        if self.eval_mode:\n",
    "            self.x = self.df[index]\n",
    "            self.y = self.labels[index]\n",
    "            return torch.Tensor(self.x), self.y\n",
    "        else:\n",
    "            self.x = self.df[index]\n",
    "            return torch.Tensor(self.x)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6507a820-b758-4e90-b6bc-ef70222ad1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = CDataset(train_df.sample(frac=1)[:len(train_df)//5])\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True, num_workers=NUM_WORKERS)\n",
    "\n",
    "val_dataset = CDataset(val_df, eval_mode=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size = batch_size, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "test_dataset = CDataset(test_df, eval_mode=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle=False, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfff4a1b-d630-4c5d-8f2e-8116aab52145",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "class BasicBlock(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inplanes: int,\n",
    "        planes: int,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        norm_layer = nn.BatchNorm1d\n",
    "        self.lin1 = nn.Linear(inplanes, planes)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.act = nn.GELU()\n",
    "        self.lin2 = nn.Linear(planes, inplanes)\n",
    "        self.bn2 = norm_layer(inplanes)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        identity = x\n",
    "\n",
    "        out = self.lin1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.act(out)\n",
    "\n",
    "        out = self.lin2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        out += identity\n",
    "        out = self.act(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aea1f718-cf59-436b-8ec9-27b644eaaf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module) :\n",
    "    def __init__(self) :\n",
    "        super().__init__()\n",
    "        self.dim = 30\n",
    "        self.embeding_dim = 512\n",
    "        self.hidden = 128\n",
    "        self.act = nn.GELU()\n",
    "        \n",
    "        self.embeding = nn.Sequential(\n",
    "            nn.Linear(self.dim,self.embeding_dim),\n",
    "            self.act,\n",
    "        ) \n",
    "        \n",
    "        self.block1 = BasicBlock(128,128)\n",
    "        self.block2 = BasicBlock(128,128)\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(self.embeding_dim,self.hidden),\n",
    "            nn.BatchNorm1d(self.hidden),\n",
    "            self.act,\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(self.hidden,self.embeding_dim),\n",
    "            nn.BatchNorm1d(self.embeding_dim),\n",
    "            self.act,            \n",
    "        )        \n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.BatchNorm1d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "                \n",
    "        \n",
    "#         freezing embeding layer        \n",
    "        for name, child in self.named_children() :\n",
    "            for param in child.parameters() :\n",
    "                # if 'embeding' in name :\n",
    "                if name == 'embeding' :\n",
    "                    param.requires_grad = False                \n",
    "        \n",
    "    def forward(self, x) :\n",
    "        \n",
    "        x_ = self.embeding(x)\n",
    "        \n",
    "        x = self.encoder(x_)\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.decoder(x)\n",
    "        \n",
    "        return x_, x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2281b347-2432-449d-a5e4-faabdf071d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer() :\n",
    "    def __init__(self, model, optimizer, train_loader, val_loader, test_loader, scheduler, device, **param) :\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.scheduler = scheduler\n",
    "        self.device = device\n",
    "        self.batch_size = param['batch_size']\n",
    "        self.epochs = param['epochs']\n",
    "        self.lr = param['lr']\n",
    "        \n",
    "        self.criterion = nn.L1Loss().to(device)\n",
    "        self.cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "        self.threshold = 0.5\n",
    "        \n",
    "    def fit(self,) :\n",
    "        self.model.to(self.device)\n",
    "        best_score = 0\n",
    "        for epoch in range(self.epochs) :\n",
    "            self.model.train()\n",
    "            train_loss = []\n",
    "            \n",
    "            for x in iter(self.train_loader) :\n",
    "                x = x.to(self.device)\n",
    "                x_, x = self.model(x)\n",
    "                \n",
    "                loss = self.criterion(x_, x)\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                train_loss.append(loss.item())\n",
    "                \n",
    "            true, pred = self.validation()\n",
    "            score = f1_score(true, pred, average='macro')\n",
    "            self.get_confusion(true, pred)\n",
    "            \n",
    "            if self.scheduler is not None :\n",
    "                self.scheduler.step()\n",
    "            \n",
    "            print(f'epoch :[{epoch}] train loss [{np.mean(train_loss)}] val score [{score}]')    \n",
    "\n",
    "            self.save_model('/'.join(saved_model.split('/')[:-1]) + '/' + str(epoch) +'.pth')\n",
    "            if best_score < score :\n",
    "                best_score = score\n",
    "                self.save_model(saved_model)\n",
    "            \n",
    "    def validation(self) :\n",
    "        self.model.eval()\n",
    "        pred_y = []\n",
    "        true_y = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for x, y in iter(self.val_loader) :\n",
    "                x = x.to(self.device)\n",
    "                y = y.to(self.device)\n",
    "                \n",
    "                x_, x = self.model(x)\n",
    "                diff = self.cos(x, x_).cpu().tolist()\n",
    "                batch_pred = np.where(np.array(diff) < self.threshold, 1, 0).tolist()\n",
    "                pred_y += batch_pred\n",
    "                true_y += y.tolist()\n",
    "                \n",
    "        return true_y, pred_y\n",
    "    \n",
    "    def predict(self) :\n",
    "        \n",
    "        self.model.eval()\n",
    "        pred_y = []\n",
    "        \n",
    "        with torch.no_grad() :\n",
    "            for x in iter(self.test_loader) :\n",
    "                x = x.to(self.device)\n",
    "                x_, x = self.model(x)\n",
    "                diff = self.cos(x, x_).cpu().tolist()\n",
    "                \n",
    "                batch_pred = np.where(np.array(diff) < self.threshold, 1, 0).tolist()\n",
    "                pred_y += batch_pred\n",
    "                \n",
    "        return pred_y\n",
    "    \n",
    "    def save_model(self, name) :\n",
    "        torch.save(self.model.state_dict(), name)\n",
    "        \n",
    "    def load_model(self, name) :\n",
    "        self.model.load_state_dict(torch.load(name))\n",
    "        \n",
    "    def get_confusion(self, true_y, pred_y) :\n",
    "        # pred_y, true_y = self.validation()\n",
    "        tn, fp, fn, tp = confusion_matrix(true_y, pred_y).ravel()\n",
    "        print('tp : ', tp, ', fp : ', fp, ', tn : ', tn, ', fn : ', fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8891703-3552-48de-9a61-c8f599d1b2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62c43387-b116-4262-b48d-c1f3d6a38745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for p in model.parameters():\n",
    "#     print(p.shape)\n",
    "#     print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65ab0bcb-f82c-42e5-a718-097ee27a7d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = AutoEncoder()\n",
    "model.eval()\n",
    "optimizer = None\n",
    "scheduler = None\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aedfbacc-e6a3-4b37-bf79-311d7e01cb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv1 = pd.read_csv('./submit_AE_split1.csv')\n",
    "csv2 = pd.read_csv('./submit_AE_split2.csv')\n",
    "csv3 = pd.read_csv('./submit_AE_split3.csv')\n",
    "csv4 = pd.read_csv('./submit_AE_split4.csv')\n",
    "csv5 = pd.read_csv('./submit_AE_split5.csv')\n",
    "csv6 = pd.read_csv('./submit_AE_split6.csv')\n",
    "csv7 = pd.read_csv('./submit_AE_split7.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c7916870-e7b4-48a4-a3f7-73066eedddec",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_arr = csv1.ID.values\n",
    "arr1 = csv1.Class.values\n",
    "arr2 = csv2.Class.values\n",
    "arr3 = csv3.Class.values\n",
    "arr4 = csv4.Class.values\n",
    "arr5 = csv5.Class.values\n",
    "arr6 = csv6.Class.values\n",
    "arr7 = csv7.Class.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8c016aa6-9555-4bdb-ad88-9c99d48e26ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = pd.DataFrame(columns=['ID', 'Class1', 'Class2', 'Class3', 'Class4', 'Class5', 'Class6', 'Class7'])\n",
    "csv['ID'] = id_arr\n",
    "csv['Class1'] = arr1\n",
    "csv['Class2'] = arr2\n",
    "csv['Class3'] = arr3\n",
    "csv['Class4'] = arr4\n",
    "csv['Class5'] = arr5\n",
    "csv['Class6'] = arr6\n",
    "csv['Class7'] = arr7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2fdd5d09-1577-4f3f-81f6-bdfd78f0013a",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv['Class'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3cedf272-7598-436a-b299-b997992337f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def set_label(x) :\n",
    "    count = collections.Counter(x)\n",
    "    if count[0] >= 5 :\n",
    "        return 0\n",
    "    else :\n",
    "        return 1\n",
    "csv['Class'] = csv.apply(lambda x : set_label(x[1:-1]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0964ee7d-1b8e-438b-ba28-daae805450f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142503, 9)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fbcca9e7-cdfc-46ca-9df0-81941a9cc5a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0010540369615627855"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal, fraud = val_df.Class.value_counts()\n",
    "fraud / (normal+fraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d1fe6b3d-38e8-47a9-890c-933db4c5d743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150.20342913358164"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.shape[0] * (fraud / (normal+fraud) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7a2ad2fe-7f3b-4859-95ac-7a01ef8d8e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    142195\n",
       "1       308\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c372c4e5-9777-4af1-874f-b2f1e9239355",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv.drop(columns=['Class1', 'Class2', 'Class3', 'Class4', 'Class5', 'Class6', 'Class7']).to_csv('./submit_AE_split.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec035972-2860-4f10-a3f1-ee919d9f511f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
