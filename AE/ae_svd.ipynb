{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27beacea-6bc4-4f6d-8024-d7661d3bb946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://dacon.io/competitions/official/235930/codeshare/5508?page=1&dtype=recent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf4fe48e-c012-4895-99e0-f3e2a7d1f658",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23c88f55-39a2-4f92-a939-eefc0aa1378f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d25a9a2-b2f0-41a5-ad29-cde480bc338e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50f138e7-da83-41ad-b588-fe85c6dbef7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 400\n",
    "lr = 5e-3\n",
    "batch_size = 1024\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-4\n",
    "seed = 42\n",
    "NUM_WORKERS = 8\n",
    "\n",
    "param = {\n",
    "            'epochs' : epochs,\n",
    "            'lr' :lr,\n",
    "            'batch_size' : batch_size,\n",
    "            'momentum' : momentum,\n",
    "            'weight_decay' : weight_decay\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d07f699-c8c6-4c60-b181-263b093cd2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed) :\n",
    "    random.seed(seed)\n",
    "    os.environ['PYHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(seed)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1dc3b08e-4bf9-442b-a9e5-2d383ef2240a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(113842, 30)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('../dataset/train.csv')\n",
    "val_df = pd.read_csv('../dataset/val.csv')\n",
    "train_df = train_df.drop(columns=['ID'])\n",
    "val_df = val_df.drop(columns=['ID'])\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e33c547b-b4c6-4314-9e68-8c4ee6fab1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduced_mat(df) :\n",
    "    u, s, v = np.linalg.svd(df, full_matrices=False)\n",
    "    s[0] = 0\n",
    "    rdf = pd.DataFrame( u @ np.diag(s) @ v)\n",
    "    return rdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e14fd2d-55f1-4b63-bb9f-4a2cdd30ab5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113842, 30)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = reduced_mat(train_df)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb456eb4-d002-456c-9730-73a828d13fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28462, 31)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val = reduced_mat(val_df.drop(columns=['Class']))\n",
    "val['Class'] = val_df['Class']\n",
    "val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c51032d7-d3a2-4bcd-9108-562207763da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDataset(Dataset):\n",
    "    def __init__(self, df, eval_mode=False):\n",
    "        self.df = df\n",
    "        self.eval_mode = eval_mode\n",
    "        if self.eval_mode:\n",
    "            self.labels = self.df['Class'].values\n",
    "            self.df = self.df.drop(columns=['Class']).values\n",
    "        else:\n",
    "            self.df = self.df.values\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        if self.eval_mode:\n",
    "            self.x = self.df[index]\n",
    "            self.y = self.labels[index]\n",
    "            return torch.Tensor(self.x), self.y\n",
    "        else:\n",
    "            self.x = self.df[index]\n",
    "            return torch.Tensor(self.x)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6507a820-b758-4e90-b6bc-ef70222ad1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CDataset(train)\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True, num_workers=NUM_WORKERS)\n",
    "\n",
    "val_dataset = CDataset(val, eval_mode=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size = batch_size, shuffle=False, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e0e6622-a750-4eaa-b2d5-55718851486a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 30])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = next(iter(train_loader))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed5927d0-5eeb-41a7-8f05-f0748d058ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 30])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y  = next(iter(val_loader))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6cdc1383-447e-4f68-85bc-df8cbde034c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0,  ..., 0, 0, 0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aea1f718-cf59-436b-8ec9-27b644eaaf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module) :\n",
    "    def __init__(self) :\n",
    "        super().__init__()\n",
    "        # self.act = nn.ReLU()\n",
    "        self.act = nn.GELU()\n",
    "        # self.act = nn.LeakyReLU()\n",
    "        \n",
    "        self.dim = 30\n",
    "        self.hidden1 = 64\n",
    "        self.hidden2 = 128\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.BatchNorm1d(self.dim),\n",
    "            nn.Linear(self.dim,self.hidden1),\n",
    "            nn.BatchNorm1d(self.hidden1),\n",
    "            self.act,\n",
    "            nn.Linear(self.hidden1,self.hidden2),\n",
    "            nn.BatchNorm1d(self.hidden2),\n",
    "            self.act,\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(self.hidden2,self.hidden1),\n",
    "            nn.BatchNorm1d(self.hidden1),\n",
    "            self.act,\n",
    "            nn.Linear(self.hidden1,self.dim),\n",
    "        )\n",
    "        \n",
    "        self.encoder2 = nn.Sequential(\n",
    "            nn.BatchNorm1d(self.dim),\n",
    "            nn.Linear(self.dim,self.hidden1),\n",
    "            nn.BatchNorm1d(self.hidden1),\n",
    "            self.act,\n",
    "            nn.Linear(self.hidden1,self.hidden2),\n",
    "            nn.BatchNorm1d(self.hidden2),\n",
    "            self.act,\n",
    "        )\n",
    "        \n",
    "        self.decoder2 = nn.Sequential(\n",
    "            nn.Linear(self.hidden2,self.hidden1),\n",
    "            nn.BatchNorm1d(self.hidden1),\n",
    "            self.act,\n",
    "            nn.Linear(self.hidden1,self.dim),\n",
    "        )        \n",
    "    \n",
    "\n",
    "          # tied auto encoder\n",
    "#         self.l1_weight = torch.randn(self.hidden1, self.dim) / torch.sqrt(torch.tensor(self.hidden1))\n",
    "#         self.l1_bias = torch.zeros(self.hidden1)\n",
    "        \n",
    "#         self.l2_weight = torch.randn(self.hidden2, self.hidden1) / torch.sqrt(torch.tensor(self.hidden2))\n",
    "#         self.l2_bias = torch.zeros(self.hidden2)\n",
    "\n",
    "#         self.encoder[1].weight = nn.Parameter(self.l1_weight)\n",
    "#         self.encoder[1].bais = nn.Parameter(self.l1_bias)\n",
    "#         self.encoder[4].weight = nn.Parameter(self.l2_weight)\n",
    "#         self.encoder[4].bias = nn.Parameter(self.l2_bias)\n",
    "\n",
    "        \n",
    "#         self.decoder[0].weight = nn.Parameter(self.l2_weight.transpose(0,1))\n",
    "#         self.encoder[0].bais = nn.Parameter(self.l2_bias)\n",
    "#         self.encoder[3].weight = nn.Parameter(self.l1_weight.transpose(0,1))\n",
    "#         self.encoder[3].bias = nn.Parameter(self.l1_bias)   \n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.BatchNorm1d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)          \n",
    "        \n",
    "    def forward(self, x) :\n",
    "        \n",
    "        x = self.encoder(x)\n",
    "        x1 = self.decoder(x)\n",
    "        \n",
    "        x = self.encoder(x1)\n",
    "        x = self.decoder(x)\n",
    "        \n",
    "        return x1, x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b4f310-d44e-4149-9e88-770c24dc3e29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2281b347-2432-449d-a5e4-faabdf071d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer() :\n",
    "    def __init__(self, model, optimizer, train_loader, val_loader, scheduler, device, **param) :\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.scheduler = scheduler\n",
    "        self.device = device\n",
    "        self.batch_size = param['batch_size']\n",
    "        self.epochs = param['epochs']\n",
    "        self.lr = param['lr']\n",
    "        \n",
    "        self.criterion = nn.L1Loss().to(device)\n",
    "        \n",
    "    def fit(self,) :\n",
    "        self.model.to(self.device)\n",
    "        best_score = 0\n",
    "        for epoch in range(self.epochs) :\n",
    "            self.model.train()\n",
    "            train_loss = []\n",
    "            \n",
    "            for x in iter(self.train_loader) :\n",
    "                x = x.to(self.device)\n",
    "                x1, _x = self.model(x)\n",
    "                \n",
    "                loss = self.criterion(x, _x)\n",
    "                loss = self.criterion(x, _x) + 0.5*self.criterion(x, x1)\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                train_loss.append(loss.item())\n",
    "                \n",
    "            score = self.validation(self.model, 0.95)\n",
    "            \n",
    "            if self.scheduler is not None :\n",
    "                self.scheduler.step(score)\n",
    "            \n",
    "            print(f'epoch :[{epoch}] train loss [{np.mean(train_loss)}] val score [{score}]')\n",
    "            # for param_group in self.optimizer.param_groups:\n",
    "            #     print(param_group['lr'])      \n",
    "            \n",
    "            # print(f'epoch :[{epoch}] train loss [{np.mean(train_loss)}] val score [{score}] lr [{self.scheduler.get_lr()}]')\n",
    "\n",
    "            if best_score < score :\n",
    "                best_score = score\n",
    "                torch.save(self.model.state_dict(), '../saved/best_model.pth')\n",
    "            \n",
    "    def validation(self, eval_model, threshold) :\n",
    "        cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "        eval_model.eval()\n",
    "        pred_y = []\n",
    "        true_y = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for x, y in iter(self.val_loader) :\n",
    "                x = x.to(self.device)\n",
    "                y = y.to(self.device)\n",
    "                \n",
    "                _, _x = self.model(x)\n",
    "                diff = cos(x, _x).cpu().tolist()\n",
    "                batch_pred = np.where(np.array(diff) < threshold, 1, 0).tolist()\n",
    "                pred_y += batch_pred\n",
    "                true_y += y.tolist()\n",
    "                \n",
    "        return f1_score(true_y, pred_y, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8891703-3552-48de-9a61-c8f599d1b2ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65ab0bcb-f82c-42e5-a718-097ee27a7d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder()\n",
    "model.eval()\n",
    "# optimizer = torch.optim.Adam(params=model.parameters(), lr = param['lr'])\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), param['lr'],\n",
    "                            momentum=param['momentum'],\n",
    "                            weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=10, threshold_mode='abs', min_lr=1e-8, verbose=True)\n",
    "# scheduler = StepLR(optimizer, step_size=50, gamma=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e978a85a-d539-4932-b2c3-f7aa76e1575b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, optimizer, train_loader, val_loader, scheduler, device, **param)\n",
    "# trainer = Trainer(model, optimizer, train_loader, val_loader, scheduler, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1c340fc-b182-4fd0-a6f7-52440a06c3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :[0] train loss [1.2751718589237757] val score [0.0010529271374420891]\n",
      "epoch :[1] train loss [1.0006130465439387] val score [0.0010529271374420891]\n",
      "epoch :[2] train loss [0.9136153581951346] val score [0.0010529271374420891]\n",
      "epoch :[3] train loss [0.8589745914297444] val score [0.0010529271374420891]\n",
      "epoch :[4] train loss [0.8147940981600966] val score [0.0010529271374420891]\n",
      "epoch :[5] train loss [0.7778674725975309] val score [0.0016862816792256323]\n",
      "epoch :[6] train loss [0.7449012313570295] val score [0.002108073923125571]\n",
      "epoch :[7] train loss [0.7167490316288812] val score [0.0035465233735341513]\n",
      "epoch :[8] train loss [0.6912844175738948] val score [0.00533006134799683]\n",
      "epoch :[9] train loss [0.6689096588109221] val score [0.0078372014167055]\n",
      "epoch :[10] train loss [0.6467952781489917] val score [0.010366347561944598]\n",
      "epoch :[11] train loss [0.6270900044058051] val score [0.013535537740313415]\n",
      "epoch :[12] train loss [0.6086725566004004] val score [0.020389710236054192]\n",
      "epoch :[13] train loss [0.5918741039931774] val score [0.02868374241164916]\n",
      "epoch :[14] train loss [0.5747927858361176] val score [0.03827765656500526]\n",
      "epoch :[15] train loss [0.5599834365504128] val score [0.04972921737179548]\n",
      "epoch :[16] train loss [0.544735390160765] val score [0.05656510602873172]\n",
      "epoch :[17] train loss [0.5312289584960256] val score [0.06970315524881986]\n",
      "epoch :[18] train loss [0.5166436098515987] val score [0.0810531531961885]\n",
      "epoch :[19] train loss [0.5041868125221559] val score [0.09131533650167362]\n",
      "epoch :[20] train loss [0.4927483805056129] val score [0.10283312517409761]\n",
      "epoch :[21] train loss [0.4814374963087695] val score [0.12275166119838503]\n",
      "epoch :[22] train loss [0.4718377199023962] val score [0.13669260251003587]\n",
      "epoch :[23] train loss [0.4608547437403883] val score [0.15567881091321825]\n",
      "epoch :[24] train loss [0.4505725947341749] val score [0.17375818177492647]\n",
      "epoch :[25] train loss [0.44142887235752176] val score [0.1927731344607477]\n",
      "epoch :[26] train loss [0.432193949552519] val score [0.21016958700566038]\n",
      "epoch :[27] train loss [0.42556075379252434] val score [0.22121124325179875]\n",
      "epoch :[28] train loss [0.41570802964270115] val score [0.2399980929441923]\n",
      "epoch :[29] train loss [0.40765823982656] val score [0.2556411487922284]\n",
      "epoch :[30] train loss [0.4008818223540272] val score [0.26463119776877575]\n",
      "epoch :[31] train loss [0.393158192347203] val score [0.27913882121570344]\n",
      "epoch :[32] train loss [0.3877001652227981] val score [0.2911029422961191]\n",
      "epoch :[33] train loss [0.38070485315152575] val score [0.2962285786164281]\n",
      "epoch :[34] train loss [0.37590849745486465] val score [0.2968648210974315]\n",
      "epoch :[35] train loss [0.36979497410357] val score [0.31604297419264443]\n",
      "epoch :[36] train loss [0.3639577603233712] val score [0.32162042404310315]\n",
      "epoch :[37] train loss [0.3584107966827495] val score [0.32976819039520483]\n",
      "epoch :[38] train loss [0.3524730649909803] val score [0.33771467607008915]\n",
      "epoch :[39] train loss [0.34772598637001856] val score [0.34351898877823195]\n",
      "epoch :[40] train loss [0.34206341446510385] val score [0.35046648558264826]\n",
      "epoch :[41] train loss [0.33778366446495056] val score [0.3559430647842963]\n",
      "epoch :[42] train loss [0.33338055493576185] val score [0.3617571239565889]\n",
      "epoch :[43] train loss [0.3294800493334021] val score [0.3641423656614744]\n",
      "epoch :[44] train loss [0.32480557369334356] val score [0.36967737820320185]\n",
      "epoch :[45] train loss [0.32122475946588175] val score [0.3771952467109006]\n",
      "epoch :[46] train loss [0.31609708815813065] val score [0.38101046089841967]\n",
      "epoch :[47] train loss [0.31185557453760077] val score [0.38662101062034143]\n",
      "epoch :[48] train loss [0.3076921331563166] val score [0.3910043960352249]\n",
      "epoch :[49] train loss [0.30550815005387577] val score [0.3941264400425853]\n",
      "epoch :[50] train loss [0.3018839633358376] val score [0.39857416104845234]\n",
      "epoch :[51] train loss [0.2962658533028194] val score [0.40325118083670713]\n",
      "epoch :[52] train loss [0.2920030206441879] val score [0.4076247609699655]\n",
      "epoch :[53] train loss [0.2893575954117945] val score [0.4099951359889641]\n",
      "epoch :[54] train loss [0.28449374650205883] val score [0.41386175553179533]\n",
      "epoch :[55] train loss [0.28231968730688095] val score [0.4168665895382268]\n",
      "epoch :[56] train loss [0.278375148241009] val score [0.41854641609020327]\n",
      "epoch :[57] train loss [0.2757739879723106] val score [0.42324849645785345]\n",
      "epoch :[58] train loss [0.2713050129158156] val score [0.4276900358766757]\n",
      "epoch :[59] train loss [0.2696784492582083] val score [0.4299778640828284]\n",
      "epoch :[60] train loss [0.2659564720732825] val score [0.4335373448195895]\n",
      "epoch :[61] train loss [0.26398444588163067] val score [0.43598670227740327]\n",
      "epoch :[62] train loss [0.26185342190521105] val score [0.43985742106441533]\n",
      "epoch :[63] train loss [0.2575266643294266] val score [0.44152309003763585]\n",
      "epoch :[64] train loss [0.25594403514904635] val score [0.44062588185211843]\n",
      "epoch :[65] train loss [0.25302317099911825] val score [0.4463765693592453]\n",
      "epoch :[66] train loss [0.2503155189167176] val score [0.44661075513525816]\n",
      "epoch :[67] train loss [0.24861593757356917] val score [0.45037244416340394]\n",
      "epoch :[68] train loss [0.24540587780731066] val score [0.4529117853959665]\n",
      "epoch :[69] train loss [0.24347370437213353] val score [0.45481960752215916]\n",
      "epoch :[70] train loss [0.24067689811012574] val score [0.4551103145535037]\n",
      "epoch :[71] train loss [0.23836272369538034] val score [0.45822616260574567]\n",
      "epoch :[72] train loss [0.23607253762228148] val score [0.46073916626989075]\n",
      "epoch :[73] train loss [0.23412117189062492] val score [0.4635140037488198]\n",
      "epoch :[74] train loss [0.2314916971538748] val score [0.46441385411261876]\n",
      "epoch :[75] train loss [0.23053443232285126] val score [0.46639388648271984]\n",
      "epoch :[76] train loss [0.22721118107438087] val score [0.46893780939019514]\n",
      "epoch :[77] train loss [0.22600547902818238] val score [0.46958854422488383]\n",
      "epoch :[78] train loss [0.22416917447532927] val score [0.4713231044652526]\n",
      "epoch :[79] train loss [0.22164096563522304] val score [0.4723623519643477]\n",
      "epoch :[80] train loss [0.22096711783004658] val score [0.4733463002658668]\n",
      "epoch :[81] train loss [0.21860061851995333] val score [0.4743350351385833]\n",
      "epoch :[82] train loss [0.21683822332748345] val score [0.4747707588583863]\n",
      "epoch :[83] train loss [0.21488508329327619] val score [0.4766351333786506]\n",
      "epoch :[84] train loss [0.2130488327571324] val score [0.4781383274463576]\n",
      "epoch :[85] train loss [0.2118767345590251] val score [0.47822507594245267]\n",
      "epoch :[86] train loss [0.2101036777187671] val score [0.4797717284495823]\n",
      "epoch :[87] train loss [0.20865878569228308] val score [0.48060328617078896]\n",
      "epoch :[88] train loss [0.2073920415714383] val score [0.48016154074904355]\n",
      "epoch :[89] train loss [0.20414038082318647] val score [0.48179885362798575]\n",
      "epoch :[90] train loss [0.20500328963888542] val score [0.48232481050198056]\n",
      "epoch :[91] train loss [0.2020116654623832] val score [0.48313874842545723]\n",
      "epoch :[92] train loss [0.20060506010694162] val score [0.48365937942799553]\n",
      "epoch :[93] train loss [0.19881922525486775] val score [0.4846970932186059]\n",
      "epoch :[94] train loss [0.19924568318362748] val score [0.4853075391287404]\n",
      "epoch :[95] train loss [0.19563529334430182] val score [0.48528089796316465]\n",
      "epoch :[96] train loss [0.19539368525147438] val score [0.4863405138005901]\n",
      "epoch :[97] train loss [0.19307524923767364] val score [0.4868694140418705]\n",
      "epoch :[98] train loss [0.1935478374361992] val score [0.48726534636341606]\n",
      "epoch :[99] train loss [0.1903837594602789] val score [0.48766363473219443]\n",
      "epoch :[100] train loss [0.19038148729928903] val score [0.4881614782894931]\n",
      "epoch :[101] train loss [0.18903271654354675] val score [0.48831437786680887]\n",
      "epoch :[102] train loss [0.18758473877928086] val score [0.4893105459112726]\n",
      "epoch :[103] train loss [0.18725459011537687] val score [0.4899364215149079]\n",
      "epoch :[104] train loss [0.18612825152065074] val score [0.4898078442946851]\n",
      "epoch :[105] train loss [0.18439844676426478] val score [0.4903095292233409]\n",
      "epoch :[106] train loss [0.18462076517088072] val score [0.4899221207244112]\n",
      "epoch :[107] train loss [0.18257821324680532] val score [0.491415070270492]\n",
      "epoch :[108] train loss [0.18226801098457404] val score [0.4887893721184494]\n",
      "epoch :[109] train loss [0.1792807938264949] val score [0.49301319833291024]\n",
      "epoch :[110] train loss [0.18012078013271093] val score [0.49065618942795397]\n",
      "epoch :[111] train loss [0.17877971128161466] val score [0.49357841705607475]\n",
      "epoch :[112] train loss [0.17807648996157305] val score [0.4924096687995117]\n",
      "epoch :[113] train loss [0.17740350549242326] val score [0.4926501712316385]\n",
      "epoch :[114] train loss [0.17509513973657573] val score [0.49377866603581316]\n",
      "epoch :[115] train loss [0.17353682765471085] val score [0.49269539903598497]\n",
      "epoch :[116] train loss [0.17424006613769702] val score [0.49488851063564226]\n",
      "epoch :[117] train loss [0.1708497479557991] val score [0.495446311984729]\n",
      "epoch :[118] train loss [0.1725292726020728] val score [0.495446311984729]\n",
      "epoch :[119] train loss [0.1708721039550645] val score [0.49584936695412385]\n",
      "epoch :[120] train loss [0.17139858127172505] val score [0.495190399619537]\n",
      "epoch :[121] train loss [0.1711012332567147] val score [0.4946989395693003]\n",
      "epoch :[122] train loss [0.1678065551178796] val score [0.4963711805215866]\n",
      "epoch :[123] train loss [0.16902882193348237] val score [0.4962891980644952]\n",
      "epoch :[124] train loss [0.16853613193546021] val score [0.49653565571916125]\n",
      "epoch :[125] train loss [0.1665716298988887] val score [0.4967836649903534]\n",
      "epoch :[126] train loss [0.16515965134437596] val score [0.4968833116584952]\n",
      "epoch :[127] train loss [0.16567627353859798] val score [0.49755431033382974]\n",
      "epoch :[128] train loss [0.16449003387242556] val score [0.49835838051321446]\n",
      "epoch :[129] train loss [0.16446335733469045] val score [0.4978772572135354]\n",
      "epoch :[130] train loss [0.1645341431722045] val score [0.49856653720005706]\n",
      "epoch :[131] train loss [0.16194757247077568] val score [0.49881091977128567]\n",
      "epoch :[132] train loss [0.16104344903890574] val score [0.4988635058393777]\n",
      "epoch :[133] train loss [0.16143926126616343] val score [0.4989865105315612]\n",
      "epoch :[134] train loss [0.15985230090362684] val score [0.4995186046094638]\n",
      "epoch :[135] train loss [0.159387205062168] val score [0.500168131985063]\n",
      "epoch :[136] train loss [0.15941493159958295] val score [0.49982378710664965]\n",
      "epoch :[137] train loss [0.15912707801908255] val score [0.49976973386902085]\n",
      "epoch :[138] train loss [0.15689117581184422] val score [0.5011666127093916]\n",
      "epoch :[139] train loss [0.1572853908208864] val score [0.5010728780586445]\n",
      "epoch :[140] train loss [0.15473056584596634] val score [0.5007747214091227]\n",
      "epoch :[141] train loss [0.15727668348699808] val score [0.5002045834260752]\n",
      "epoch :[142] train loss [0.15525757135557278] val score [0.5018113319760472]\n",
      "epoch :[143] train loss [0.15603723403598582] val score [0.5012417956126185]\n",
      "epoch :[144] train loss [0.15390444693288632] val score [0.5014305207951026]\n",
      "epoch :[145] train loss [0.1528702306428126] val score [0.5020806397106172]\n",
      "epoch :[146] train loss [0.15258245010461127] val score [0.5025085587540383]\n",
      "epoch :[147] train loss [0.1525071562666978] val score [0.5018496644700556]\n",
      "epoch :[148] train loss [0.15150457288005523] val score [0.5024889799243277]\n",
      "epoch :[149] train loss [0.15136377021138156] val score [0.5024107877872322]\n",
      "epoch :[150] train loss [0.14929428763155425] val score [0.5031017812242772]\n",
      "epoch :[151] train loss [0.14816556817718915] val score [0.502922607244078]\n",
      "epoch :[152] train loss [0.14742044572319304] val score [0.5034431308819058]\n",
      "epoch :[153] train loss [0.14979121847344296] val score [0.5034431308819058]\n",
      "epoch :[154] train loss [0.14823609424222792] val score [0.5030021103174734]\n",
      "epoch :[155] train loss [0.14609469233879022] val score [0.5042204960438823]\n",
      "epoch :[156] train loss [0.1475027333945036] val score [0.5035645347973339]\n",
      "epoch :[157] train loss [0.14669944385864905] val score [0.5040345367007412]\n",
      "epoch :[158] train loss [0.14509830590603606] val score [0.5042619801495867]\n",
      "epoch :[159] train loss [0.14471490075811744] val score [0.5040345367007412]\n",
      "epoch :[160] train loss [0.1445121811037617] val score [0.5042619801495867]\n",
      "epoch :[161] train loss [0.14466523897967168] val score [0.5030818209475632]\n",
      "epoch :[162] train loss [0.1424127326213888] val score [0.5052542539367272]\n",
      "epoch :[163] train loss [0.14335947018116713] val score [0.5038497386062798]\n",
      "epoch :[164] train loss [0.14134723713089312] val score [0.5056653079249706]\n",
      "epoch :[165] train loss [0.14067321829497814] val score [0.5059940894907594]\n",
      "epoch :[166] train loss [0.14121901456798827] val score [0.5042412307842953]\n",
      "epoch :[167] train loss [0.14064606724839127] val score [0.5057744766125964]\n",
      "epoch :[168] train loss [0.14120221896363155] val score [0.5052757412323783]\n",
      "epoch :[169] train loss [0.14087910604264056] val score [0.5058621163983007]\n",
      "epoch :[170] train loss [0.13979045368198836] val score [0.5059060386862002]\n",
      "epoch :[171] train loss [0.1386061814347548] val score [0.5065957945188201]\n",
      "epoch :[172] train loss [0.13834223663434386] val score [0.5064385444658186]\n",
      "epoch :[173] train loss [0.13909924635663629] val score [0.49868851987059815]\n",
      "epoch :[174] train loss [0.13917669840157032] val score [0.5076287346028844]\n",
      "epoch :[175] train loss [0.13676422155861342] val score [0.5074887300750673]\n",
      "epoch :[176] train loss [0.1378076351247728] val score [0.5074189977289437]\n",
      "epoch :[177] train loss [0.13777109647967986] val score [0.5077694669030222]\n",
      "epoch :[178] train loss [0.13806992137272442] val score [0.5052327827637979]\n",
      "epoch :[179] train loss [0.1370343126888786] val score [0.5072108662237494]\n",
      "epoch :[180] train loss [0.13522046132545387] val score [0.5076990091768251]\n",
      "epoch :[181] train loss [0.13525000074878335] val score [0.5088981871219624]\n",
      "epoch :[182] train loss [0.13542550835492356] val score [0.5075819860393259]\n",
      "epoch :[183] train loss [0.13482856058648654] val score [0.508873666476829]\n",
      "epoch :[184] train loss [0.13533819633136904] val score [0.5087758106357905]\n",
      "epoch :[185] train loss [0.13495622907898255] val score [0.507887306776647]\n",
      "epoch :[186] train loss [0.13193547552717583] val score [0.5088002406888651]\n",
      "epoch :[187] train loss [0.13397973516423786] val score [0.5096698904628365]\n",
      "epoch :[188] train loss [0.13396145084074565] val score [0.5095438749195526]\n",
      "epoch :[189] train loss [0.1323793194522815] val score [0.5085811765868412]\n",
      "epoch :[190] train loss [0.1326798259147576] val score [0.5103092935808844]\n",
      "epoch :[191] train loss [0.131107306640063] val score [0.5096698904628365]\n",
      "epoch :[192] train loss [0.13186692812346987] val score [0.5058182624691518]\n",
      "epoch :[193] train loss [0.13209435589877622] val score [0.5094685563519323]\n",
      "epoch :[194] train loss [0.1316974103184683] val score [0.510205923049196]\n",
      "epoch :[195] train loss [0.13087837704058206] val score [0.5104390915474141]\n",
      "epoch :[196] train loss [0.13145624127771174] val score [0.5109649344081599]\n",
      "epoch :[197] train loss [0.13096970239920275] val score [0.5117471580196297]\n",
      "epoch :[198] train loss [0.13028831194554055] val score [0.5115561305312071]\n",
      "epoch :[199] train loss [0.12991445385185735] val score [0.5127816142559692]\n",
      "epoch :[200] train loss [0.12964367420811737] val score [0.5116924316901726]\n",
      "epoch :[201] train loss [0.1291069136267262] val score [0.5119719279728446]\n",
      "epoch :[202] train loss [0.12955669672893627] val score [0.5126791485619634]\n",
      "epoch :[203] train loss [0.12797211230333363] val score [0.512224192991472]\n",
      "epoch :[204] train loss [0.12894500426149794] val score [0.5124790681913186]\n",
      "epoch :[205] train loss [0.1277887662872672] val score [0.5123851808837837]\n",
      "epoch :[206] train loss [0.1282358593972666] val score [0.5126791485619634]\n",
      "epoch :[207] train loss [0.12758092223001377] val score [0.5136528942112656]\n",
      "epoch :[208] train loss [0.12782698896314418] val score [0.5139203414106085]\n",
      "epoch :[209] train loss [0.126345136535487] val score [0.5129968985469517]\n",
      "epoch :[210] train loss [0.12644917245155998] val score [0.5147404778395023]\n",
      "epoch :[211] train loss [0.12577449164486357] val score [0.5151860206968166]\n",
      "epoch :[212] train loss [0.12539440413404787] val score [0.5148698623413901]\n",
      "epoch :[213] train loss [0.12623976091189043] val score [0.5146479941364613]\n",
      "epoch :[214] train loss [0.12630886045683706] val score [0.5133483125822201]\n",
      "epoch :[215] train loss [0.12671372274469053] val score [0.51139312669336]\n",
      "epoch :[216] train loss [0.1256437422707677] val score [0.5104836306894012]\n",
      "epoch :[217] train loss [0.12521665949108346] val score [0.5159951128168169]\n",
      "epoch :[218] train loss [0.12503952905535698] val score [0.5150590584983387]\n",
      "epoch :[219] train loss [0.12551138935876743] val score [0.5163933990380217]\n",
      "epoch :[220] train loss [0.1237697221471795] val score [0.5160940646732926]\n",
      "epoch :[221] train loss [0.12297340801783971] val score [0.5161934272593166]\n",
      "epoch :[222] train loss [0.1241929524445108] val score [0.5141275788118123]\n",
      "epoch :[223] train loss [0.12451946389462266] val score [0.5176297214636381]\n",
      "epoch :[224] train loss [0.1230997137193169] val score [0.5162367941875406]\n",
      "epoch :[225] train loss [0.12273159330444676] val score [0.518200473567068]\n",
      "epoch :[226] train loss [0.1229132720535355] val score [0.5138248938354258]\n",
      "epoch :[227] train loss [0.12328900629654527] val score [0.518200473567068]\n",
      "epoch :[228] train loss [0.12367593829653092] val score [0.5158965681369707]\n",
      "epoch :[229] train loss [0.12219659751281142] val score [0.5174809595761681]\n",
      "epoch :[230] train loss [0.12269183986687235] val score [0.5191957806087343]\n",
      "epoch :[231] train loss [0.12242799105920962] val score [0.5172798227561672]\n",
      "epoch :[232] train loss [0.1235389195249549] val score [0.5181283768978883]\n",
      "epoch :[233] train loss [0.12206263221534235] val score [0.5169007730278659]\n",
      "epoch :[234] train loss [0.12124448449217848] val score [0.5175878375655507]\n",
      "epoch :[235] train loss [0.1218137029292328] val score [0.5125646172689218]\n",
      "epoch :[236] train loss [0.12106735704998885] val score [0.5202345463914608]\n",
      "epoch :[237] train loss [0.12195209047890135] val score [0.520993687140364]\n",
      "epoch :[238] train loss [0.1208197480466749] val score [0.5216940362003688]\n",
      "epoch :[239] train loss [0.12227926083973475] val score [0.5198351612363772]\n",
      "epoch :[240] train loss [0.12090878068868603] val score [0.5186097085074197]\n",
      "epoch :[241] train loss [0.11876124968486172] val score [0.5212385283228532]\n",
      "epoch :[242] train loss [0.1200588159263134] val score [0.5214212567602095]\n",
      "epoch :[243] train loss [0.12028349603393249] val score [0.5204716716451692]\n",
      "epoch :[244] train loss [0.11925678713513273] val score [0.5147656563298548]\n",
      "epoch :[245] train loss [0.11965100014848369] val score [0.520993687140364]\n",
      "epoch :[246] train loss [0.11941745584564549] val score [0.5225018773524192]\n",
      "epoch :[247] train loss [0.11930522276088595] val score [0.5190617415383179]\n",
      "epoch :[248] train loss [0.11904858990705439] val score [0.5227627571806402]\n",
      "epoch :[249] train loss [0.1186493318527937] val score [0.5227627571806402]\n",
      "epoch :[250] train loss [0.11819954223132559] val score [0.5229872511333062]\n",
      "epoch :[251] train loss [0.11876492687900152] val score [0.516849764856344]\n",
      "epoch :[252] train loss [0.11823251211483564] val score [0.5220179068274238]\n",
      "epoch :[253] train loss [0.11826253575938088] val score [0.5191379396403556]\n",
      "epoch :[254] train loss [0.11836153734475374] val score [0.5240451807183246]\n",
      "epoch :[255] train loss [0.11732986722407597] val score [0.5256003075659932]\n",
      "epoch :[256] train loss [0.11705453614039081] val score [0.5248100428135503]\n",
      "epoch :[257] train loss [0.11892138667670744] val score [0.5242815630340075]\n",
      "epoch :[258] train loss [0.11677240926240172] val score [0.5251525663924234]\n",
      "epoch :[259] train loss [0.11816135787272028] val score [0.5208805121100971]\n",
      "epoch :[260] train loss [0.11581330207575645] val score [0.5245203246845707]\n",
      "epoch :[261] train loss [0.1173870054605816] val score [0.5232586959277539]\n",
      "epoch :[262] train loss [0.11701681478215116] val score [0.5218887689295447]\n",
      "epoch :[263] train loss [0.11673521303704806] val score [0.5245203246845707]\n",
      "epoch :[264] train loss [0.11674963982243623] val score [0.5229872511333062]\n",
      "epoch :[265] train loss [0.11573625382568155] val score [0.5210455680675096]\n",
      "Epoch   267: reducing learning rate of group 0 to 2.5000e-03.\n",
      "epoch :[266] train loss [0.11671209341979452] val score [0.5232586959277539]\n",
      "epoch :[267] train loss [0.11331011913716793] val score [0.5239981858942214]\n",
      "epoch :[268] train loss [0.11397608289761203] val score [0.5255501421253772]\n",
      "epoch :[269] train loss [0.11294095145006265] val score [0.5233955987980123]\n",
      "epoch :[270] train loss [0.11279888451099396] val score [0.5259544412021552]\n",
      "epoch :[271] train loss [0.11244322931660074] val score [0.5271562082777036]\n",
      "epoch :[272] train loss [0.11276420950889587] val score [0.5255000817260972]\n",
      "epoch :[273] train loss [0.11233124343146171] val score [0.5291075832574624]\n",
      "epoch :[274] train loss [0.11202373588457704] val score [0.5288190867947024]\n",
      "epoch :[275] train loss [0.11202611095671143] val score [0.5265217210941973]\n",
      "epoch :[276] train loss [0.11201233183965087] val score [0.527807788775894]\n",
      "epoch :[277] train loss [0.11221380984144551] val score [0.5278628850040702]\n",
      "epoch :[278] train loss [0.11194364640063473] val score [0.5173039098141923]\n",
      "epoch :[279] train loss [0.11212093635861363] val score [0.5273174685939379]\n",
      "epoch :[280] train loss [0.1124012973824782] val score [0.5248100428135503]\n",
      "epoch :[281] train loss [0.111949528634016] val score [0.5291656913917538]\n",
      "epoch :[282] train loss [0.11249293074277895] val score [0.5283644422515518]\n",
      "epoch :[283] train loss [0.112249996047467] val score [0.5279734532456781]\n",
      "epoch :[284] train loss [0.11086669923471552] val score [0.5311011325592798]\n",
      "epoch :[285] train loss [0.11290373759610313] val score [0.5283644422515518]\n",
      "epoch :[286] train loss [0.1112707208708993] val score [0.52646959335204]\n",
      "epoch :[287] train loss [0.11177256031494055] val score [0.5319974973495886]\n",
      "epoch :[288] train loss [0.1120025824223246] val score [0.5281961073209688]\n",
      "epoch :[289] train loss [0.11080744177369135] val score [0.5326578249890803]\n",
      "epoch :[290] train loss [0.11438836636287826] val score [0.5238111338497043]\n",
      "epoch :[291] train loss [0.11011351917737297] val score [0.5296949282041331]\n",
      "epoch :[292] train loss [0.11262988824663418] val score [0.5280289262871035]\n",
      "epoch :[293] train loss [0.11102798594427961] val score [0.5320627606169218]\n",
      "epoch :[294] train loss [0.11133517704105803] val score [0.5317381185273695]\n",
      "epoch :[295] train loss [0.11181877866121274] val score [0.5285339454591927]\n",
      "epoch :[296] train loss [0.11169260993067708] val score [0.5337513068776042]\n",
      "epoch :[297] train loss [0.11152594263798424] val score [0.5318674745935222]\n",
      "epoch :[298] train loss [0.11029669289876308] val score [0.5300541602621511]\n",
      "epoch :[299] train loss [0.11027205189956087] val score [0.5288190867947024]\n",
      "epoch :[300] train loss [0.1107211389711925] val score [0.5343874885654999]\n",
      "epoch :[301] train loss [0.10958199269537415] val score [0.5289340788243417]\n",
      "epoch :[302] train loss [0.11062248550089342] val score [0.5281961073209688]\n",
      "epoch :[303] train loss [0.11053054201017533] val score [0.52646959335204]\n",
      "epoch :[304] train loss [0.10882629660357322] val score [0.5313539912675205]\n",
      "epoch :[305] train loss [0.1104011519013771] val score [0.5336120410903045]\n",
      "epoch :[306] train loss [0.10998914537153073] val score [0.530418674245508]\n",
      "epoch :[307] train loss [0.10996499710849353] val score [0.5359354424299558]\n",
      "epoch :[308] train loss [0.11067039745726756] val score [0.5329268395235559]\n",
      "epoch :[309] train loss [0.11061630883653249] val score [0.5348933373594558]\n",
      "epoch :[310] train loss [0.10883347909631473] val score [0.5303575492794963]\n",
      "epoch :[311] train loss [0.11135807354003191] val score [0.5364724046131849]\n",
      "epoch :[312] train loss [0.10976717348343559] val score [0.5349664116227172]\n",
      "epoch :[313] train loss [0.10899668872090322] val score [0.5328593190650799]\n",
      "epoch :[314] train loss [0.10970479629135557] val score [0.5344591518178194]\n",
      "epoch :[315] train loss [0.10990994722981538] val score [0.5371791564892391]\n",
      "epoch :[316] train loss [0.1097011286765337] val score [0.5315453214638971]\n",
      "epoch :[317] train loss [0.10820635960304312] val score [0.5334045484287037]\n",
      "epoch :[318] train loss [0.10958868724160961] val score [0.5384001968205163]\n",
      "epoch :[319] train loss [0.10900093701535038] val score [0.5384001968205163]\n",
      "epoch :[320] train loss [0.10978979258132833] val score [0.5291656913917538]\n",
      "epoch :[321] train loss [0.11024267379460591] val score [0.5321281928224817]\n",
      "epoch :[322] train loss [0.10799473005213908] val score [0.5384001968205163]\n",
      "epoch :[323] train loss [0.10864761125828538] val score [0.5378234758406146]\n",
      "epoch :[324] train loss [0.10923864107046809] val score [0.5384001968205163]\n",
      "epoch :[325] train loss [0.10915492641340409] val score [0.5273714616187877]\n",
      "epoch :[326] train loss [0.10821879814778056] val score [0.5364724046131849]\n",
      "epoch :[327] train loss [0.10845326426039849] val score [0.5379051136624544]\n",
      "epoch :[328] train loss [0.10760864063299128] val score [0.5374993808721963]\n",
      "Epoch   330: reducing learning rate of group 0 to 1.2500e-03.\n",
      "epoch :[329] train loss [0.10830289764063698] val score [0.5341736815755249]\n",
      "epoch :[330] train loss [0.10635574793975268] val score [0.535859617797017]\n",
      "epoch :[331] train loss [0.10723676678857633] val score [0.5355584867643545]\n",
      "epoch :[332] train loss [0.10810160284329738] val score [0.5377420849055329]\n",
      "epoch :[333] train loss [0.1073376463859209] val score [0.5314813827142935]\n",
      "epoch :[334] train loss [0.1060743051847177] val score [0.535708620902091]\n",
      "epoch :[335] train loss [0.1056385166676981] val score [0.538483598837718]\n",
      "epoch :[336] train loss [0.10659401198582989] val score [0.5401186927826271]\n",
      "epoch :[337] train loss [0.10736626147159509] val score [0.537986999638786]\n",
      "epoch :[338] train loss [0.10616839337827903] val score [0.5422365635673053]\n",
      "epoch :[339] train loss [0.10553791633407984] val score [0.5414816272113812]\n",
      "epoch :[340] train loss [0.10531869929816041] val score [0.5395917341648675]\n",
      "epoch :[341] train loss [0.10632224746846727] val score [0.5385672581308983]\n",
      "epoch :[342] train loss [0.10633383744529315] val score [0.5374993808721963]\n",
      "epoch :[343] train loss [0.10639023893911924] val score [0.5355584867643545]\n",
      "epoch :[344] train loss [0.10665349941700697] val score [0.5392459571044942]\n",
      "epoch :[345] train loss [0.10595095357192415] val score [0.537338789759385]\n",
      "epoch :[346] train loss [0.10629442533744234] val score [0.537660939598084]\n",
      "epoch :[347] train loss [0.10574374447709747] val score [0.5440121239883796]\n",
      "epoch :[348] train loss [0.10668169307921614] val score [0.5368627250477384]\n",
      "epoch :[349] train loss [0.10597573247339044] val score [0.5408372899692211]\n",
      "epoch :[350] train loss [0.10549246772591557] val score [0.5406558907783732]\n",
      "epoch :[351] train loss [0.10679545186992202] val score [0.5351131775458509]\n",
      "epoch :[352] train loss [0.10539366704012666] val score [0.5276432455522588]\n",
      "epoch :[353] train loss [0.10560814078365054] val score [0.5403859911539594]\n",
      "epoch :[354] train loss [0.10706319200939365] val score [0.5444220066101826]\n",
      "epoch :[355] train loss [0.1070195586819734] val score [0.5343874885654999]\n",
      "epoch :[356] train loss [0.10544631776532956] val score [0.5423323635070021]\n",
      "epoch :[357] train loss [0.10642739598240171] val score [0.5430121488132839]\n",
      "epoch :[358] train loss [0.10556645598262548] val score [0.5445253863286927]\n",
      "epoch :[359] train loss [0.10508176079019904] val score [0.5355584867643545]\n",
      "epoch :[360] train loss [0.10428986625213708] val score [0.5367842009326989]\n",
      "epoch :[361] train loss [0.10596213542989322] val score [0.5326578249890803]\n",
      "epoch :[362] train loss [0.10526070444445525] val score [0.5391601905961616]\n",
      "epoch :[363] train loss [0.10751007118129305] val score [0.5415748961876343]\n",
      "epoch :[364] train loss [0.10423061524384789] val score [0.5397662695236801]\n",
      "epoch :[365] train loss [0.1048766762417342] val score [0.5451534662641078]\n",
      "epoch :[366] train loss [0.10547558783686586] val score [0.5425249383473707]\n",
      "epoch :[367] train loss [0.10589831388954606] val score [0.5429140394301281]\n",
      "epoch :[368] train loss [0.10473965534142085] val score [0.54204592959581]\n",
      "epoch :[369] train loss [0.10524699424526521] val score [0.5371791564892391]\n",
      "epoch :[370] train loss [0.10569114051759243] val score [0.5401186927826271]\n",
      "epoch :[371] train loss [0.10537592980212399] val score [0.538317050749187]\n",
      "epoch :[372] train loss [0.10576009510883264] val score [0.5465620424772634]\n",
      "epoch :[373] train loss [0.10548988330577101] val score [0.5435077960045478]\n",
      "epoch :[374] train loss [0.10466024020154562] val score [0.5438093350896822]\n",
      "epoch :[375] train loss [0.10510636919311114] val score [0.5427188253653]\n",
      "epoch :[376] train loss [0.10584062890016607] val score [0.5465620424772634]\n",
      "epoch :[377] train loss [0.10586314109553184] val score [0.547009208656243]\n",
      "epoch :[378] train loss [0.10398561041802168] val score [0.547692673578974]\n",
      "epoch :[379] train loss [0.10566687517400299] val score [0.5385672581308983]\n",
      "epoch :[380] train loss [0.1049492462937321] val score [0.5414816272113812]\n",
      "epoch :[381] train loss [0.10483403503894806] val score [0.5492284130390661]\n",
      "epoch :[382] train loss [0.10544592048972845] val score [0.5391601905961616]\n",
      "epoch :[383] train loss [0.10543544976306814] val score [0.5404756665856641]\n",
      "epoch :[384] train loss [0.10420637677556702] val score [0.5385672581308983]\n",
      "epoch :[385] train loss [0.1052255140883582] val score [0.5415748961876343]\n",
      "epoch :[386] train loss [0.10470175111134138] val score [0.5461214675696098]\n",
      "epoch :[387] train loss [0.10491335125906127] val score [0.53758003866768]\n",
      "epoch :[388] train loss [0.10405030640374337] val score [0.5450478465525356]\n",
      "epoch :[389] train loss [0.10438305252630796] val score [0.5489870801613018]\n",
      "epoch :[390] train loss [0.10414805981729712] val score [0.5395917341648675]\n",
      "epoch :[391] train loss [0.10667842506830182] val score [0.5401186927826271]\n",
      "Epoch   393: reducing learning rate of group 0 to 6.2500e-04.\n",
      "epoch :[392] train loss [0.1044720231023218] val score [0.5461214675696098]\n",
      "epoch :[393] train loss [0.10353989493367928] val score [0.5411116199984652]\n",
      "epoch :[394] train loss [0.1037991337611207] val score [0.5360114859479371]\n",
      "epoch :[395] train loss [0.10395079212529319] val score [0.5444220066101826]\n",
      "epoch :[396] train loss [0.10471530990408999] val score [0.5432093818224616]\n",
      "epoch :[397] train loss [0.10327672891850982] val score [0.5480402825299603]\n",
      "epoch :[398] train loss [0.10362275849495615] val score [0.5454726209606728]\n",
      "epoch :[399] train loss [0.10298249098871436] val score [0.5488671189923648]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c3a528-b82e-4abd-8bb8-a77aa77bb6dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4105eeb3-b7fd-4de2-91d7-28d327d17b3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd1bf94-b4b9-482b-8bba-c857a9fdd0fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
