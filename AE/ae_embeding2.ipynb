{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27beacea-6bc4-4f6d-8024-d7661d3bb946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://dacon.io/competitions/official/235930/codeshare/5508?page=1&dtype=recent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf4fe48e-c012-4895-99e0-f3e2a7d1f658",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23c88f55-39a2-4f92-a939-eefc0aa1378f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d25a9a2-b2f0-41a5-ad29-cde480bc338e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50f138e7-da83-41ad-b588-fe85c6dbef7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "lr = 1e-3\n",
    "batch_size = 512\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-4\n",
    "seed = 42\n",
    "NUM_WORKERS = 8\n",
    "saved_model = '../saved/ae_embeding2/best_model.pth'\n",
    "\n",
    "param = {\n",
    "            'epochs' : epochs,\n",
    "            'lr' :lr,\n",
    "            'batch_size' : batch_size,\n",
    "            'momentum' : momentum,\n",
    "            'weight_decay' : weight_decay\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d07f699-c8c6-4c60-b181-263b093cd2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed) :\n",
    "    random.seed(seed)\n",
    "    os.environ['PYHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(seed)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1dc3b08e-4bf9-442b-a9e5-2d383ef2240a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(113842, 30)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('../dataset/train.csv')\n",
    "val_df = pd.read_csv('../dataset/val.csv')\n",
    "train_df = train_df.drop(columns=['ID'])\n",
    "val_df = val_df.drop(columns=['ID'])\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc65c1d2-4ef7-44f6-813a-66a58ffb79c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CDataset(Dataset) :\n",
    "#     def __init__(self, df, eval_mode=False) :\n",
    "#         self.df = df\n",
    "#         self.eval_mode = eval_mode\n",
    "#         if self.eval_mode :\n",
    "#             self.labels = self.df['Class']\n",
    "#             self.df = self.df.drop(columns=['Class'])\n",
    "        \n",
    "#     def __getitem__(self, idx) :\n",
    "#         if self.eval_mode :\n",
    "#             self.x = self.df.iloc[idx, 1:]\n",
    "#             self.y = self.labels[idx]\n",
    "#             return torch.tensor(self.x, dtype=torch.float32),torch.tensor(self.y)\n",
    "        \n",
    "#         else :\n",
    "#             self.x = self.df.iloc[idx, 1:]\n",
    "#             return torch.tensor(self.x, dtype=torch.float32)\n",
    "        \n",
    "#     def __len__(self) :\n",
    "#         return len(self.df)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c51032d7-d3a2-4bcd-9108-562207763da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDataset(Dataset):\n",
    "    def __init__(self, df, eval_mode=False):\n",
    "        self.df = df\n",
    "        self.eval_mode = eval_mode\n",
    "        if self.eval_mode:\n",
    "            self.labels = self.df['Class'].values\n",
    "            self.df = self.df.drop(columns=['Class']).values\n",
    "        else:\n",
    "            self.df = self.df.values\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        if self.eval_mode:\n",
    "            self.x = self.df[index]\n",
    "            self.y = self.labels[index]\n",
    "            return torch.Tensor(self.x), self.y\n",
    "        else:\n",
    "            self.x = self.df[index]\n",
    "            return torch.Tensor(self.x)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ceca45-55c2-48a8-86da-7e471c29caad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6507a820-b758-4e90-b6bc-ef70222ad1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CDataset(train_df)\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True, num_workers=NUM_WORKERS)\n",
    "\n",
    "val_dataset = CDataset(val_df, eval_mode=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size = batch_size, shuffle=False, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5e0e6622-a750-4eaa-b2d5-55718851486a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 30])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = next(iter(train_loader))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed5927d0-5eeb-41a7-8f05-f0748d058ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 30])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y  = next(iter(val_loader))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aea1f718-cf59-436b-8ec9-27b644eaaf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module) :\n",
    "    def __init__(self) :\n",
    "        super().__init__()\n",
    "        self.dim = 30\n",
    "        self.embeding_dim = 1024\n",
    "        self.hidden = 256\n",
    "        self.act = nn.GELU()\n",
    "        \n",
    "        self.embeding = nn.Sequential(\n",
    "            nn.Linear(self.dim,self.embeding_dim),\n",
    "            nn.GELU(),\n",
    "            # self.act\n",
    "        )\n",
    "        self.encoder = nn.Sequential(\n",
    "            # nn.BatchNorm1d(self.embeding_dim),\n",
    "            nn.Linear(self.embeding_dim,self.hidden),\n",
    "            nn.BatchNorm1d(self.hidden),\n",
    "            self.act,\n",
    "            # nn.Linear(self.hidden,self.hidden//2),\n",
    "            # nn.BatchNorm1d(self.hidden//2),\n",
    "            # self.act,\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(self.hidden,self.embeding_dim),\n",
    "            nn.BatchNorm1d(self.embeding_dim),\n",
    "            self.act,            \n",
    "            # nn.Linear(self.hidden,self.embeding_dim),\n",
    "            # nn.BatchNorm1d(self.embeding_dim),\n",
    "            # self.act,\n",
    "            # nn.Linear(64,30),\n",
    "        )\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.BatchNorm1d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)  \n",
    "                \n",
    "        \n",
    "#         freezing embeding layer        \n",
    "        for name, child in self.named_children() :\n",
    "            for param in child.parameters() :\n",
    "                if name == 'embeding' :\n",
    "                    param.requires_grad = False                \n",
    "        \n",
    "    def forward(self, x) :\n",
    "        x_ = self.embeding(x)\n",
    "        x = self.encoder(x_)\n",
    "        x = self.decoder(x)\n",
    "        return x_, x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2281b347-2432-449d-a5e4-faabdf071d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer() :\n",
    "    def __init__(self, model, optimizer, train_loader, val_loader, scheduler, device, **param) :\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.scheduler = scheduler\n",
    "        self.device = device\n",
    "        self.batch_size = param['batch_size']\n",
    "        self.epochs = param['epochs']\n",
    "        self.lr = param['lr']\n",
    "        \n",
    "        self.criterion = nn.L1Loss().to(device)\n",
    "        \n",
    "    def fit(self,) :\n",
    "        self.model.to(self.device)\n",
    "        best_score = 0\n",
    "        for epoch in range(self.epochs) :\n",
    "            self.model.train()\n",
    "            train_loss = []\n",
    "            \n",
    "            for x in iter(self.train_loader) :\n",
    "                x = x.to(self.device)\n",
    "                x_, x = self.model(x)\n",
    "                \n",
    "                loss = self.criterion(x_, x)\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                train_loss.append(loss.item())\n",
    "                # self.scheduler.step()\n",
    "                \n",
    "            score = self.validation(self.model, 0.95)\n",
    "            \n",
    "            if self.scheduler is not None :\n",
    "                self.scheduler.step(score)\n",
    "            \n",
    "            print(f'epoch :[{epoch}] train loss [{np.mean(train_loss)}] val score [{score}]')\n",
    "            for param_group in self.optimizer.param_groups:\n",
    "                print(param_group['lr'])      \n",
    "            \n",
    "            # print(f'epoch :[{epoch}] train loss [{np.mean(train_loss)}] val score [{score}] lr [{self.scheduler.get_lr()}]')\n",
    "\n",
    "            if best_score < score :\n",
    "                best_score = score\n",
    "                torch.save(self.model.state_dict(), saved_model)\n",
    "            \n",
    "    def validation(self, eval_model, threshold) :\n",
    "        cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "        eval_model.eval()\n",
    "        pred_y = []\n",
    "        true_y = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for x, y in iter(self.val_loader) :\n",
    "                x = x.to(self.device)\n",
    "                y = y.to(self.device)\n",
    "                \n",
    "                x_, x = self.model(x)\n",
    "                diff = cos(x, x_).cpu().tolist()\n",
    "                batch_pred = np.where(np.array(diff) < threshold, 1, 0).tolist()\n",
    "                pred_y += batch_pred\n",
    "                true_y += y.tolist()\n",
    "                \n",
    "        return f1_score(true_y, pred_y, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c8891703-3552-48de-9a61-c8f599d1b2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9accd8-f4cf-4ecc-8a55-cb3fd189dc0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3563fa59-dfc5-47a2-b46c-dbe99838d415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "65ab0bcb-f82c-42e5-a718-097ee27a7d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder()\n",
    "model.eval()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr = param['lr'])\n",
    "\n",
    "# optimizer = torch.optim.SGD(model.parameters(), param['lr'],\n",
    "#                             momentum=param['momentum'],\n",
    "#                             weight_decay=param['weight_decay'])\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=10, threshold_mode='abs', min_lr=1e-8, verbose=True)\n",
    "# scheduler = StepLR(optimizer, step_size=50, gamma=0.2)\n",
    "scheduler = None\n",
    "\n",
    "# scheduler = lr_scheduler.LambdaLR(optimizer, lambda epoch : 0.1 **(epoch //30))\n",
    "# scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, \n",
    "#                                                 epochs              = param['epochs'], \n",
    "#                                                 steps_per_epoch     = int(len(train_dataset)/param['batch_size'])+1,\n",
    "#                                                 max_lr              = param['lr'], \n",
    "#                                                 pct_start           = 0.05, \n",
    "#                                                 div_factor          = 5, \n",
    "#                                                 final_div_factor    = 5e+4)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e978a85a-d539-4932-b2c3-f7aa76e1575b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, optimizer, train_loader, val_loader, scheduler, device, **param)\n",
    "# trainer = Trainer(model, optimizer, train_loader, val_loader, scheduler, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b1c340fc-b182-4fd0-a6f7-52440a06c3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :[0] train loss [0.09985051359229559] val score [0.4913398693937736]\n",
      "0.001\n",
      "epoch :[1] train loss [0.0452007337936906] val score [0.5156034575278333]\n",
      "0.001\n",
      "epoch :[2] train loss [0.03732989737638711] val score [0.5168843874195664]\n",
      "0.001\n",
      "epoch :[3] train loss [0.03409483398189726] val score [0.5430121488132839]\n",
      "0.001\n",
      "epoch :[4] train loss [0.03178482785019105] val score [0.5441140534215738]\n",
      "0.001\n",
      "epoch :[5] train loss [0.030117362136263485] val score [0.5401186927826271]\n",
      "0.001\n",
      "epoch :[6] train loss [0.02898469896394041] val score [0.5847044184696032]\n",
      "0.001\n",
      "epoch :[7] train loss [0.02855351392697593] val score [0.6029354027598012]\n",
      "0.001\n",
      "epoch :[8] train loss [0.027446805303206357] val score [0.6071081826004132]\n",
      "0.001\n",
      "epoch :[9] train loss [0.027331080613449014] val score [0.7094766927103557]\n",
      "0.001\n",
      "epoch :[10] train loss [0.026334997391821022] val score [0.730971061881369]\n",
      "0.001\n",
      "epoch :[11] train loss [0.026037416349879296] val score [0.7655703273293624]\n",
      "0.001\n",
      "epoch :[12] train loss [0.02572709585920043] val score [0.808369294415656]\n",
      "0.001\n",
      "epoch :[13] train loss [0.02551033836476204] val score [0.8045965667777433]\n",
      "0.001\n",
      "epoch :[14] train loss [0.025259499809800776] val score [0.833113452596645]\n",
      "0.001\n",
      "epoch :[15] train loss [0.024494254485507717] val score [0.8376267560436427]\n",
      "0.001\n",
      "epoch :[16] train loss [0.024633893592809347] val score [0.8376267560436427]\n",
      "0.001\n",
      "epoch :[17] train loss [0.024453760671842795] val score [0.8844834793761085]\n",
      "0.001\n",
      "epoch :[18] train loss [0.024297185192060044] val score [0.872984830495149]\n",
      "0.001\n",
      "epoch :[19] train loss [0.024061139163481814] val score [0.8422634702634115]\n",
      "0.001\n",
      "epoch :[20] train loss [0.023847345459053603] val score [0.8967110829723166]\n",
      "0.001\n",
      "epoch :[21] train loss [0.023458595542161988] val score [0.8621517488551477]\n",
      "0.001\n",
      "epoch :[22] train loss [0.02339872702822557] val score [0.8967110829723166]\n",
      "0.001\n",
      "epoch :[23] train loss [0.023044505402980364] val score [0.8967110829723166]\n",
      "0.001\n",
      "epoch :[24] train loss [0.023182617408545027] val score [0.9031202878275757]\n",
      "0.001\n",
      "epoch :[25] train loss [0.023563292169851573] val score [0.9031202878275757]\n",
      "0.001\n",
      "epoch :[26] train loss [0.023068877421486538] val score [0.9097393418694286]\n",
      "0.001\n",
      "epoch :[27] train loss [0.022712783190534522] val score [0.9165787375726882]\n",
      "0.001\n",
      "epoch :[28] train loss [0.022626880481170966] val score [0.9097393418694286]\n",
      "0.001\n",
      "epoch :[29] train loss [0.02267223289194663] val score [0.9165787375726882]\n",
      "0.001\n",
      "epoch :[30] train loss [0.022473404693496603] val score [0.9165787375726882]\n",
      "0.001\n",
      "epoch :[31] train loss [0.022393734081577292] val score [0.9165787375726882]\n",
      "0.001\n",
      "epoch :[32] train loss [0.02209230095164792] val score [0.9165787375726882]\n",
      "0.001\n",
      "epoch :[33] train loss [0.0223627884625854] val score [0.9165787375726882]\n",
      "0.001\n",
      "epoch :[34] train loss [0.021765530627270983] val score [0.9165787375726882]\n",
      "0.001\n",
      "epoch :[35] train loss [0.021944144460886317] val score [0.9165787375726882]\n",
      "0.001\n",
      "epoch :[36] train loss [0.02157077460127962] val score [0.9165787375726882]\n",
      "0.001\n",
      "epoch :[37] train loss [0.02145173413169491] val score [0.9165787375726882]\n",
      "0.001\n",
      "epoch :[38] train loss [0.02107435498269684] val score [0.9165787375726882]\n",
      "0.001\n",
      "epoch :[39] train loss [0.02156182285398245] val score [0.9165787375726882]\n",
      "0.001\n",
      "epoch :[40] train loss [0.021311273597882468] val score [0.9165787375726882]\n",
      "0.001\n",
      "epoch :[41] train loss [0.021681642322696645] val score [0.9165787375726882]\n",
      "0.001\n",
      "epoch :[42] train loss [0.021281926337245335] val score [0.9165787375726882]\n",
      "0.001\n",
      "epoch :[43] train loss [0.021060012861451493] val score [0.9236496787663914]\n",
      "0.001\n",
      "epoch :[44] train loss [0.020956562761000188] val score [0.9165787375726882]\n",
      "0.001\n",
      "epoch :[45] train loss [0.021236908237863283] val score [0.9165787375726882]\n",
      "0.001\n",
      "epoch :[46] train loss [0.020994629815321065] val score [0.9236496787663914]\n",
      "0.001\n",
      "epoch :[47] train loss [0.020951204703527716] val score [0.9236496787663914]\n",
      "0.001\n",
      "epoch :[48] train loss [0.02096121389452251] val score [0.9165787375726882]\n",
      "0.001\n",
      "epoch :[49] train loss [0.020726403831232823] val score [0.9236496787663914]\n",
      "0.001\n",
      "epoch :[50] train loss [0.020690447984956572] val score [0.9165787375726882]\n",
      "0.001\n",
      "epoch :[51] train loss [0.020996218279939596] val score [0.9165787375726882]\n",
      "0.001\n",
      "epoch :[52] train loss [0.021169617304352902] val score [0.9236496787663914]\n",
      "0.001\n",
      "epoch :[53] train loss [0.020932833897993972] val score [0.9236496787663914]\n",
      "0.001\n",
      "epoch :[54] train loss [0.02046629521711792] val score [0.9236496787663914]\n",
      "0.001\n",
      "epoch :[55] train loss [0.020787685399565995] val score [0.9165787375726882]\n",
      "0.001\n",
      "epoch :[56] train loss [0.02056381090506577] val score [0.9236496787663914]\n",
      "0.001\n",
      "epoch :[57] train loss [0.020476145298124162] val score [0.9236496787663914]\n",
      "0.001\n",
      "epoch :[58] train loss [0.02056320325676101] val score [0.9165787375726882]\n",
      "0.001\n",
      "epoch :[59] train loss [0.020968469089490148] val score [0.9236496787663914]\n",
      "0.001\n",
      "epoch :[60] train loss [0.020701465543543275] val score [0.9236496787663914]\n",
      "0.001\n",
      "epoch :[61] train loss [0.020461882339297657] val score [0.9236496787663914]\n",
      "0.001\n",
      "epoch :[62] train loss [0.021076611781935522] val score [0.9236496787663914]\n",
      "0.001\n",
      "epoch :[63] train loss [0.020811591088571356] val score [0.9236496787663914]\n",
      "0.001\n",
      "epoch :[64] train loss [0.02062922091778752] val score [0.9236496787663914]\n",
      "0.001\n",
      "epoch :[65] train loss [0.020264780036102763] val score [0.9236496787663914]\n",
      "0.001\n",
      "epoch :[66] train loss [0.02038317151584834] val score [0.9165787375726882]\n",
      "0.001\n",
      "epoch :[67] train loss [0.020603705920078562] val score [0.9165787375726882]\n",
      "0.001\n",
      "epoch :[68] train loss [0.020320897525168052] val score [0.9236496787663914]\n",
      "0.001\n",
      "epoch :[69] train loss [0.020632211711976024] val score [0.9165787375726882]\n",
      "0.001\n",
      "epoch :[70] train loss [0.020279516014917818] val score [0.9236496787663914]\n",
      "0.001\n",
      "epoch :[71] train loss [0.020525866154698244] val score [0.9236496787663914]\n",
      "0.001\n",
      "epoch :[72] train loss [0.020088711035158066] val score [0.9236496787663914]\n",
      "0.001\n",
      "epoch :[73] train loss [0.020138200610508566] val score [0.9165787375726882]\n",
      "0.001\n",
      "epoch :[74] train loss [0.020192060644650674] val score [0.9236496787663914]\n",
      "0.001\n",
      "epoch :[75] train loss [0.02011163664288451] val score [0.9236496787663914]\n",
      "0.001\n",
      "epoch :[76] train loss [0.020234482062170323] val score [0.9236496787663914]\n",
      "0.001\n",
      "epoch :[77] train loss [0.020541094201763116] val score [0.9236496787663914]\n",
      "0.001\n",
      "epoch :[78] train loss [0.02026145623771332] val score [0.9165787375726882]\n",
      "0.001\n",
      "epoch :[79] train loss [0.02072948344352534] val score [0.9236496787663914]\n",
      "0.001\n",
      "epoch :[80] train loss [0.02006454731133086] val score [0.9236496787663914]\n",
      "0.001\n",
      "epoch :[81] train loss [0.019890647941172925] val score [0.9165787375726882]\n",
      "0.001\n",
      "epoch :[82] train loss [0.020425217439140705] val score [0.9236496787663914]\n",
      "0.001\n",
      "epoch :[83] train loss [0.01988855111224769] val score [0.9236496787663914]\n",
      "0.001\n",
      "epoch :[84] train loss [0.01988678287313792] val score [0.9236496787663914]\n",
      "0.001\n",
      "epoch :[85] train loss [0.020062994186854147] val score [0.9236496787663914]\n",
      "0.001\n",
      "epoch :[86] train loss [0.020213199654101257] val score [0.9165787375726882]\n",
      "0.001\n",
      "epoch :[87] train loss [0.019926766117391564] val score [0.9236496787663914]\n",
      "0.001\n",
      "epoch :[88] train loss [0.020058149747517077] val score [0.9236496787663914]\n",
      "0.001\n",
      "epoch :[89] train loss [0.019949023223444485] val score [0.9236496787663914]\n",
      "0.001\n",
      "epoch :[90] train loss [0.01981568312264077] val score [0.9236496787663914]\n",
      "0.001\n",
      "epoch :[91] train loss [0.019885985272614946] val score [0.9236496787663914]\n",
      "0.001\n",
      "epoch :[92] train loss [0.020203721705373094] val score [0.9236496787663914]\n",
      "0.001\n",
      "epoch :[93] train loss [0.020072073876156133] val score [0.9236496787663914]\n",
      "0.001\n",
      "epoch :[94] train loss [0.019849531235582626] val score [0.9236496787663914]\n",
      "0.001\n",
      "epoch :[95] train loss [0.01980086777259015] val score [0.9236496787663914]\n",
      "0.001\n",
      "epoch :[96] train loss [0.019864628024633155] val score [0.9236496787663914]\n",
      "0.001\n",
      "epoch :[97] train loss [0.019708937472526] val score [0.9236496787663914]\n",
      "0.001\n",
      "epoch :[98] train loss [0.019710375292585836] val score [0.9236496787663914]\n",
      "0.001\n",
      "epoch :[99] train loss [0.019697731569609835] val score [0.9236496787663914]\n",
      "0.001\n"
     ]
    }
   ],
   "source": [
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c3a528-b82e-4abd-8bb8-a77aa77bb6dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4105eeb3-b7fd-4de2-91d7-28d327d17b3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b897dc-6205-43a3-bf83-73d6f8d47d71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8308878f-f08b-4d44-9b59-fb6640310b26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0964ee7d-1b8e-438b-ba28-daae805450f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcca9e7-cdfc-46ca-9df0-81941a9cc5a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fe6b3d-38e8-47a9-890c-933db4c5d743",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2ad2fe-7f3b-4859-95ac-7a01ef8d8e32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
