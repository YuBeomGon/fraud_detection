{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27beacea-6bc4-4f6d-8024-d7661d3bb946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://dacon.io/competitions/official/235930/codeshare/5508?page=1&dtype=recent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf4fe48e-c012-4895-99e0-f3e2a7d1f658",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23c88f55-39a2-4f92-a939-eefc0aa1378f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d25a9a2-b2f0-41a5-ad29-cde480bc338e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50f138e7-da83-41ad-b588-fe85c6dbef7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "lr = 1e-3\n",
    "batch_size = 512\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-4\n",
    "seed = 42\n",
    "NUM_WORKERS = 8\n",
    "saved_model = '../saved/ae_embeding/best_model.pth'\n",
    "\n",
    "param = {\n",
    "            'epochs' : epochs,\n",
    "            'lr' :lr,\n",
    "            'batch_size' : batch_size,\n",
    "            'momentum' : momentum,\n",
    "            'weight_decay' : weight_decay\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d07f699-c8c6-4c60-b181-263b093cd2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed) :\n",
    "    random.seed(seed)\n",
    "    os.environ['PYHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(seed)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1dc3b08e-4bf9-442b-a9e5-2d383ef2240a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(113842, 30)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('../dataset/train.csv')\n",
    "val_df = pd.read_csv('../dataset/val.csv')\n",
    "train_df = train_df.drop(columns=['ID'])\n",
    "val_df = val_df.drop(columns=['ID'])\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc65c1d2-4ef7-44f6-813a-66a58ffb79c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CDataset(Dataset) :\n",
    "#     def __init__(self, df, eval_mode=False) :\n",
    "#         self.df = df\n",
    "#         self.eval_mode = eval_mode\n",
    "#         if self.eval_mode :\n",
    "#             self.labels = self.df['Class']\n",
    "#             self.df = self.df.drop(columns=['Class'])\n",
    "        \n",
    "#     def __getitem__(self, idx) :\n",
    "#         if self.eval_mode :\n",
    "#             self.x = self.df.iloc[idx, 1:]\n",
    "#             self.y = self.labels[idx]\n",
    "#             return torch.tensor(self.x, dtype=torch.float32),torch.tensor(self.y)\n",
    "        \n",
    "#         else :\n",
    "#             self.x = self.df.iloc[idx, 1:]\n",
    "#             return torch.tensor(self.x, dtype=torch.float32)\n",
    "        \n",
    "#     def __len__(self) :\n",
    "#         return len(self.df)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c51032d7-d3a2-4bcd-9108-562207763da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDataset(Dataset):\n",
    "    def __init__(self, df, eval_mode=False):\n",
    "        self.df = df\n",
    "        self.eval_mode = eval_mode\n",
    "        if self.eval_mode:\n",
    "            self.labels = self.df['Class'].values\n",
    "            self.df = self.df.drop(columns=['Class']).values\n",
    "        else:\n",
    "            self.df = self.df.values\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        if self.eval_mode:\n",
    "            self.x = self.df[index]\n",
    "            self.y = self.labels[index]\n",
    "            return torch.Tensor(self.x), self.y\n",
    "        else:\n",
    "            self.x = self.df[index]\n",
    "            return torch.Tensor(self.x)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ceca45-55c2-48a8-86da-7e471c29caad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6507a820-b758-4e90-b6bc-ef70222ad1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CDataset(train_df)\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True, num_workers=NUM_WORKERS)\n",
    "\n",
    "val_dataset = CDataset(val_df, eval_mode=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size = batch_size, shuffle=False, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e0e6622-a750-4eaa-b2d5-55718851486a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 30])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = next(iter(train_loader))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed5927d0-5eeb-41a7-8f05-f0748d058ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 30])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y  = next(iter(val_loader))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aea1f718-cf59-436b-8ec9-27b644eaaf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module) :\n",
    "    def __init__(self) :\n",
    "        super().__init__()\n",
    "        self.dim = 30\n",
    "        self.embeding_dim = 1024\n",
    "        self.hidden = 256\n",
    "        self.act = nn.GELU()\n",
    "        \n",
    "        self.embeding = nn.Sequential(\n",
    "            nn.Linear(self.dim,self.embeding_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(self.embeding_dim,self.hidden),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(self.hidden,self.embeding_dim),\n",
    "            # self.act\n",
    "        )\n",
    "        self.encoder = nn.Sequential(\n",
    "            # nn.LayerNorm(self.embeding_dim),\n",
    "            # nn.BatchNorm1d(self.embeding_dim),\n",
    "            nn.Linear(self.embeding_dim,self.hidden),\n",
    "            nn.BatchNorm1d(self.hidden),\n",
    "            self.act,\n",
    "            # nn.Linear(64,128),\n",
    "            # nn.BatchNorm1d(128),\n",
    "            # nn.LeakyReLU(),\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(self.hidden,self.embeding_dim),\n",
    "            nn.BatchNorm1d(self.embeding_dim),\n",
    "            self.act,\n",
    "            # nn.Linear(64,30),\n",
    "        )\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.BatchNorm1d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)  \n",
    "                \n",
    "        \n",
    "# #         freezing embeding layer        \n",
    "#         for name, child in self.named_children() :\n",
    "#             for param in child.parameters() :\n",
    "#                 if name == 'embeding' :\n",
    "#                     param.requires_grad = False                \n",
    "        \n",
    "    def forward(self, x) :\n",
    "        x_ = self.embeding(x)\n",
    "        x = self.encoder(x_)\n",
    "        x = self.decoder(x)\n",
    "        return x_, x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2281b347-2432-449d-a5e4-faabdf071d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer() :\n",
    "    def __init__(self, model, optimizer, train_loader, val_loader, scheduler, device, **param) :\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.scheduler = scheduler\n",
    "        self.device = device\n",
    "        self.batch_size = param['batch_size']\n",
    "        self.epochs = param['epochs']\n",
    "        self.lr = param['lr']\n",
    "        \n",
    "        self.criterion = nn.L1Loss().to(device)\n",
    "        \n",
    "    def fit(self,) :\n",
    "        self.model.to(self.device)\n",
    "        best_score = 0\n",
    "        for epoch in range(self.epochs) :\n",
    "            self.model.train()\n",
    "            train_loss = []\n",
    "            \n",
    "            for x in iter(self.train_loader) :\n",
    "                x = x.to(self.device)\n",
    "                x_, x = self.model(x)\n",
    "                \n",
    "                loss = self.criterion(x_, x)\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                train_loss.append(loss.item())\n",
    "                # self.scheduler.step()\n",
    "                \n",
    "            score = self.validation(self.model, 0.95)\n",
    "            \n",
    "            if self.scheduler is not None :\n",
    "                self.scheduler.step(score)\n",
    "            \n",
    "            print(f'epoch :[{epoch}] train loss [{np.mean(train_loss)}] val score [{score}]')\n",
    "            for param_group in self.optimizer.param_groups:\n",
    "                print(param_group['lr'])      \n",
    "            \n",
    "            # print(f'epoch :[{epoch}] train loss [{np.mean(train_loss)}] val score [{score}] lr [{self.scheduler.get_lr()}]')\n",
    "\n",
    "            if best_score < score :\n",
    "                best_score = score\n",
    "                torch.save(self.model.state_dict(), saved_model)\n",
    "            \n",
    "    def validation(self, eval_model, threshold) :\n",
    "        cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "        eval_model.eval()\n",
    "        pred_y = []\n",
    "        true_y = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for x, y in iter(self.val_loader) :\n",
    "                x = x.to(self.device)\n",
    "                y = y.to(self.device)\n",
    "                \n",
    "                x_, x = self.model(x)\n",
    "                diff = cos(x, x_).cpu().tolist()\n",
    "                batch_pred = np.where(np.array(diff) < threshold, 1, 0).tolist()\n",
    "                pred_y += batch_pred\n",
    "                true_y += y.tolist()\n",
    "                \n",
    "        return f1_score(true_y, pred_y, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8891703-3552-48de-9a61-c8f599d1b2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9accd8-f4cf-4ecc-8a55-cb3fd189dc0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3563fa59-dfc5-47a2-b46c-dbe99838d415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65ab0bcb-f82c-42e5-a718-097ee27a7d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder()\n",
    "model.eval()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr = param['lr'])\n",
    "\n",
    "# optimizer = torch.optim.SGD(model.parameters(), param['lr'],\n",
    "#                             momentum=param['momentum'],\n",
    "#                             weight_decay=param['weight_decay'])\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=10, threshold_mode='abs', min_lr=1e-8, verbose=True)\n",
    "# scheduler = StepLR(optimizer, step_size=50, gamma=0.2)\n",
    "scheduler = None\n",
    "\n",
    "# scheduler = lr_scheduler.LambdaLR(optimizer, lambda epoch : 0.1 **(epoch //30))\n",
    "# scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, \n",
    "#                                                 epochs              = param['epochs'], \n",
    "#                                                 steps_per_epoch     = int(len(train_dataset)/param['batch_size'])+1,\n",
    "#                                                 max_lr              = param['lr'], \n",
    "#                                                 pct_start           = 0.05, \n",
    "#                                                 div_factor          = 5, \n",
    "#                                                 final_div_factor    = 5e+4)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "767e4be5-a114-4e61-a4d8-4ef3d1865c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n"
     ]
    }
   ],
   "source": [
    "for param_group in optimizer.param_groups:\n",
    "    print(param_group['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e978a85a-d539-4932-b2c3-f7aa76e1575b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, optimizer, train_loader, val_loader, scheduler, device, **param)\n",
    "# trainer = Trainer(model, optimizer, train_loader, val_loader, scheduler, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1c340fc-b182-4fd0-a6f7-52440a06c3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :[0] train loss [0.044021268487978944] val score [0.011643347261451348]\n",
      "0.001\n",
      "epoch :[1] train loss [0.026487220993323977] val score [0.006202024658914319]\n",
      "0.001\n",
      "epoch :[2] train loss [0.025029654902794435] val score [0.5049338607994625]\n",
      "0.001\n",
      "epoch :[3] train loss [0.022255458380408887] val score [0.49584936695412385]\n",
      "0.001\n",
      "epoch :[4] train loss [0.01611600038825196] val score [0.009709313361527569]\n",
      "0.001\n",
      "epoch :[5] train loss [0.024050163560350647] val score [0.2537700272680949]\n",
      "0.001\n",
      "epoch :[6] train loss [0.013621002055637772] val score [0.4965062180473739]\n",
      "0.001\n",
      "epoch :[7] train loss [0.007662450843553305] val score [0.4975727726879557]\n",
      "0.001\n",
      "epoch :[8] train loss [0.0064365537847588545] val score [0.49844928455628396]\n",
      "0.001\n",
      "epoch :[9] train loss [0.005437482381761575] val score [0.49786528351152043]\n",
      "0.001\n",
      "epoch :[10] train loss [0.004868136980412152] val score [0.4984227685258613]\n",
      "0.001\n",
      "epoch :[11] train loss [0.004070885547054639] val score [0.4964349533801596]\n",
      "0.001\n",
      "epoch :[12] train loss [0.003499369181623691] val score [0.49775895535556736]\n",
      "0.001\n",
      "epoch :[13] train loss [0.0032411747979576547] val score [0.49852881582888453]\n",
      "0.001\n",
      "epoch :[14] train loss [0.0030663962044748957] val score [0.0010529271374420891]\n",
      "0.001\n",
      "epoch :[15] train loss [0.005109314314734959] val score [0.0010529271374420891]\n",
      "0.001\n",
      "epoch :[16] train loss [0.002026877003448343] val score [0.4986436498150431]\n",
      "0.001\n",
      "epoch :[17] train loss [0.0018707264333257595] val score [0.4986436498150431]\n",
      "0.001\n",
      "epoch :[18] train loss [0.0017586456254936938] val score [0.4962032038233472]\n",
      "0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbc744e-f318-4fdd-bd5c-19f814597117",
   "metadata": {},
   "source": [
    "## inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4105eeb3-b7fd-4de2-91d7-28d327d17b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder()\n",
    "model.load_state_dict(torch.load(saved_model))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b897dc-6205-43a3-bf83-73d6f8d47d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('../dataset/test.csv')\n",
    "test_df = test_df.drop(columns=['ID'])\n",
    "test_dataset = CDataset(test_df, eval_mode=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle=False, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8308878f-f08b-4d44-9b59-fb6640310b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0964ee7d-1b8e-438b-ba28-daae805450f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(model, threshold, test_loader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "    pred = []\n",
    "    with torch.no_grad():\n",
    "        for x in iter(test_loader):\n",
    "            x = x.float().to(device)\n",
    "            \n",
    "            x_, x = model(x)\n",
    "            \n",
    "            diff = cos(x, x_).cpu().tolist()\n",
    "            batch_pred = np.where(np.array(diff)<threshold, 1,0).tolist()\n",
    "            pred += batch_pred\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcca9e7-cdfc-46ca-9df0-81941a9cc5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = prediction(model, 0.95, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fe6b3d-38e8-47a9-890c-933db4c5d743",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('../dataset/sample_submission.csv')\n",
    "submit['Class'] = preds\n",
    "submit.to_csv('./submit_AE_embeding.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2ad2fe-7f3b-4859-95ac-7a01ef8d8e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c2846f-209e-4b4f-b6d1-7f785d8c6c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.read_csv('../dataset/val.csv')\n",
    "val_y = val_df['Class'].values\n",
    "val_df = val_df.drop(columns=['ID', 'Class'])\n",
    "val_dataset = CDataset(val_df, eval_mode=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size = batch_size, shuffle=False, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a6d29d-537e-4047-bdb0-79be28e43a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf305059-9d60-49be-bb66-9eb6b500bfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred = prediction(model, 0.95, val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba53ff55-afba-410a-95f3-c87c283b7a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(val_y, val_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb2a7f4-7d72-455d-8502-c14334946c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(val_y, val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadde9c1-1c0e-4afc-bf84-d5a663aab009",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(val_y, val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182acc9e-db6b-4fc8-9e3f-2d53c79e6ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = np.where(np.array(val_y) != np.array(val_pred))[0]\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3276ac-9c2a-4d90-8c10-75578f01b09d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
