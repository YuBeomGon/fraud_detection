{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27beacea-6bc4-4f6d-8024-d7661d3bb946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://dacon.io/competitions/official/235930/codeshare/5508?page=1&dtype=recent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf4fe48e-c012-4895-99e0-f3e2a7d1f658",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23c88f55-39a2-4f92-a939-eefc0aa1378f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d25a9a2-b2f0-41a5-ad29-cde480bc338e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50f138e7-da83-41ad-b588-fe85c6dbef7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "lr = 1e-3\n",
    "batch_size = 512\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-4\n",
    "seed = 42\n",
    "NUM_WORKERS = 8\n",
    "saved_model = '../saved/ae_embeding3/best_model.pth'\n",
    "\n",
    "param = {\n",
    "            'epochs' : epochs,\n",
    "            'lr' :lr,\n",
    "            'batch_size' : batch_size,\n",
    "            'momentum' : momentum,\n",
    "            'weight_decay' : weight_decay\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d07f699-c8c6-4c60-b181-263b093cd2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed) :\n",
    "    random.seed(seed)\n",
    "    os.environ['PYHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(seed)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1dc3b08e-4bf9-442b-a9e5-2d383ef2240a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(113842, 30)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('../dataset/train.csv')\n",
    "val_df = pd.read_csv('../dataset/val.csv')\n",
    "train_df = train_df.drop(columns=['ID'])\n",
    "val_df = val_df.drop(columns=['ID'])\n",
    "test_df = pd.read_csv('../dataset/test.csv')\n",
    "test_df = test_df.drop(columns=['ID'])\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de6a6b3b-1460-4a9a-9a02-18ff2efe8c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler\n",
    "# col=[col for col in val_df.columns if col not in ['ID','Class']]\n",
    "\n",
    "# for i in col:\n",
    "#     sc=RobustScaler()\n",
    "#     # sc = MinMaxScaler(feature_range=(-1,1))\n",
    "#     train_df[i]=sc.fit_transform(train_df[i].values.reshape(-1,1))\n",
    "    \n",
    "# for i in col:\n",
    "#     sc=RobustScaler()\n",
    "#     # sc = MinMaxScaler(feature_range=(-1,1))\n",
    "#     val_df[i]=sc.fit_transform(val_df[i].values.reshape(-1,1))\n",
    "    \n",
    "# for i in col:\n",
    "#     sc=RobustScaler()\n",
    "#     # sc = MinMaxScaler(feature_range=(-1,1))\n",
    "#     test_df[i]=sc.fit_transform(test_df[i].values.reshape(-1,1))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc65c1d2-4ef7-44f6-813a-66a58ffb79c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CDataset(Dataset) :\n",
    "#     def __init__(self, df, eval_mode=False) :\n",
    "#         self.df = df\n",
    "#         self.eval_mode = eval_mode\n",
    "#         if self.eval_mode :\n",
    "#             self.labels = self.df['Class']\n",
    "#             self.df = self.df.drop(columns=['Class'])\n",
    "        \n",
    "#     def __getitem__(self, idx) :\n",
    "#         if self.eval_mode :\n",
    "#             self.x = self.df.iloc[idx, 1:]\n",
    "#             self.y = self.labels[idx]\n",
    "#             return torch.tensor(self.x, dtype=torch.float32),torch.tensor(self.y)\n",
    "        \n",
    "#         else :\n",
    "#             self.x = self.df.iloc[idx, 1:]\n",
    "#             return torch.tensor(self.x, dtype=torch.float32)\n",
    "        \n",
    "#     def __len__(self) :\n",
    "#         return len(self.df)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c51032d7-d3a2-4bcd-9108-562207763da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDataset(Dataset):\n",
    "    def __init__(self, df, eval_mode=False):\n",
    "        self.df = df\n",
    "        self.eval_mode = eval_mode\n",
    "        if self.eval_mode:\n",
    "            self.labels = self.df['Class'].values\n",
    "            self.df = self.df.drop(columns=['Class']).values\n",
    "        else:\n",
    "            self.df = self.df.values\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        if self.eval_mode:\n",
    "            self.x = self.df[index]\n",
    "            self.y = self.labels[index]\n",
    "            return torch.Tensor(self.x), self.y\n",
    "        else:\n",
    "            self.x = self.df[index]\n",
    "            return torch.Tensor(self.x)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ceca45-55c2-48a8-86da-7e471c29caad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6507a820-b758-4e90-b6bc-ef70222ad1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CDataset(train_df)\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True, num_workers=NUM_WORKERS)\n",
    "\n",
    "val_dataset = CDataset(val_df, eval_mode=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size = batch_size, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "test_dataset = CDataset(test_df, eval_mode=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle=False, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e0e6622-a750-4eaa-b2d5-55718851486a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 30])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = next(iter(train_loader))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed5927d0-5eeb-41a7-8f05-f0748d058ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 30])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y  = next(iter(val_loader))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aea1f718-cf59-436b-8ec9-27b644eaaf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module) :\n",
    "    def __init__(self) :\n",
    "        super().__init__()\n",
    "        self.dim = 30\n",
    "        self.embeding_dim = 2048\n",
    "        self.hidden = 512\n",
    "        self.act = nn.GELU()\n",
    "        \n",
    "        self.embeding = nn.Sequential(\n",
    "            nn.Linear(self.dim,self.embeding_dim),\n",
    "            # nn.BatchNorm1d(self.embeding_dim),\n",
    "            nn.GELU(),\n",
    "        ) \n",
    "        self.encoder = nn.Sequential(\n",
    "            # nn.BatchNorm1d(self.embeding_dim),\n",
    "            nn.Linear(self.embeding_dim,self.hidden),\n",
    "            nn.BatchNorm1d(self.hidden),\n",
    "            self.act,\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(self.hidden,self.embeding_dim),\n",
    "            nn.BatchNorm1d(self.embeding_dim),\n",
    "            self.act,            \n",
    "        )\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.BatchNorm1d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "                \n",
    "        \n",
    "#         freezing embeding layer        \n",
    "        for name, child in self.named_children() :\n",
    "            for param in child.parameters() :\n",
    "                # if 'embeding' in name :\n",
    "                if name == 'embeding' :\n",
    "                    param.requires_grad = False                \n",
    "        \n",
    "    def forward(self, x) :\n",
    "        \n",
    "        x_ = self.embeding(x)\n",
    "        \n",
    "        x = self.encoder(x_)\n",
    "        x = self.decoder(x)\n",
    "        return x_, x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2281b347-2432-449d-a5e4-faabdf071d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer() :\n",
    "    def __init__(self, model, optimizer, train_loader, val_loader, test_loader, scheduler, device, **param) :\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.scheduler = scheduler\n",
    "        self.device = device\n",
    "        self.batch_size = param['batch_size']\n",
    "        self.epochs = param['epochs']\n",
    "        self.lr = param['lr']\n",
    "        \n",
    "        self.criterion = nn.L1Loss().to(device)\n",
    "        # self.criterion = nn.MSELoss().to(device)\n",
    "        self.cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "        \n",
    "    def fit(self,) :\n",
    "        self.model.to(self.device)\n",
    "        best_score = 0\n",
    "        for epoch in range(self.epochs) :\n",
    "            self.model.train()\n",
    "            train_loss = []\n",
    "            \n",
    "            for x in iter(self.train_loader) :\n",
    "                x = x.to(self.device)\n",
    "                x_, x = self.model(x)\n",
    "                \n",
    "                loss = self.criterion(x_, x)\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                train_loss.append(loss.item())\n",
    "                # self.scheduler.step()\n",
    "                \n",
    "            score, _, _ = self.validation(self.model, 0.95)\n",
    "            \n",
    "            if self.scheduler is not None :\n",
    "                self.scheduler.step()\n",
    "            \n",
    "            print(f'epoch :[{epoch}] train loss [{np.mean(train_loss)}] val score [{score}]')\n",
    "            for param_group in self.optimizer.param_groups:\n",
    "                print(param_group['lr'])      \n",
    "            \n",
    "            # print(f'epoch :[{epoch}] train loss [{np.mean(train_loss)}] val score [{score}] lr [{self.scheduler.get_lr()}]')\n",
    "\n",
    "            if best_score < score :\n",
    "                best_score = score\n",
    "                # torch.save(self.model.state_dict(), saved_model)\n",
    "            \n",
    "    def validation(self, model, threshold) :\n",
    "        # cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "        model.eval()\n",
    "        pred_y = []\n",
    "        true_y = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for x, y in iter(self.val_loader) :\n",
    "                x = x.to(self.device)\n",
    "                y = y.to(self.device)\n",
    "                \n",
    "                x_, x = model(x)\n",
    "                # diff = torch.linalg.norm(x - x_, dim=1).cpu().tolist()\n",
    "                diff = self.cos(x, x_).cpu().tolist()\n",
    "                batch_pred = np.where(np.array(diff) < threshold, 1, 0).tolist()\n",
    "                pred_y += batch_pred\n",
    "                true_y += y.tolist()\n",
    "            print(confusion_matrix(true_y, pred_y))\n",
    "                \n",
    "        return f1_score(true_y, pred_y, average='macro'), pred_y, true_y\n",
    "    \n",
    "    def predict(self, model, threshold) :\n",
    "        \n",
    "        model.eval()\n",
    "        pred_y = []\n",
    "        \n",
    "        with torch.no_grad() :\n",
    "            for x in iter(self.test_loader) :\n",
    "                x = x.to(self.device)\n",
    "                x_, x = model(x)\n",
    "                diff = self.cos(x, x_).cpu().tolist()\n",
    "                \n",
    "                batch_pred = np.where(np.array(diff) < threshold, 1, 0).tolist()\n",
    "                pred_y += batch_pred\n",
    "                \n",
    "        return pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8891703-3552-48de-9a61-c8f599d1b2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62c43387-b116-4262-b48d-c1f3d6a38745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for p in model.parameters():\n",
    "#     print(p.shape)\n",
    "#     print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de9accd8-f4cf-4ecc-8a55-cb3fd189dc0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5686, -1.4019,  0.1380],\n",
       "        [-1.6804,  0.4622, -0.0730]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(2,3)\n",
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3563fa59-dfc5-47a2-b46c-dbe99838d415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.5191, 1.7444])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linalg.norm(a,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65ab0bcb-f82c-42e5-a718-097ee27a7d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder()\n",
    "model.eval()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr = param['lr'], weight_decay=1e-4)\n",
    "\n",
    "# optimizer = torch.optim.SGD(model.parameters(), param['lr'],\n",
    "#                             momentum=param['momentum'],\n",
    "#                             weight_decay=param['weight_decay'])\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=10, threshold_mode='abs', min_lr=1e-8, verbose=True)\n",
    "# scheduler = StepLR(optimizer, step_size=20, gamma=0.5)\n",
    "scheduler = None\n",
    "\n",
    "# scheduler = lr_scheduler.LambdaLR(optimizer, lambda epoch : 0.1 **(epoch //30))\n",
    "# scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, \n",
    "#                                                 epochs              = param['epochs'], \n",
    "#                                                 steps_per_epoch     = int(len(train_dataset)/param['batch_size'])+1,\n",
    "#                                                 max_lr              = param['lr'], \n",
    "#                                                 pct_start           = 0.05, \n",
    "#                                                 div_factor          = 5, \n",
    "#                                                 final_div_factor    = 5e+4)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e978a85a-d539-4932-b2c3-f7aa76e1575b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, optimizer, train_loader, val_loader, test_loader, scheduler, device, **param)\n",
    "# trainer = Trainer(model, optimizer, train_loader, val_loader, scheduler, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1c340fc-b182-4fd0-a6f7-52440a06c3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[27681   751]\n",
      " [    5    25]]\n",
      "epoch :[0] train loss [0.08623232572201656] val score [0.5242815630340075]\n",
      "0.001\n",
      "[[28322   110]\n",
      " [    5    25]]\n",
      "epoch :[1] train loss [0.04011361230782864] val score [0.650502096316857]\n",
      "0.001\n",
      "[[28427     5]\n",
      " [    5    25]]\n",
      "epoch :[2] train loss [0.03246125136188862] val score [0.9165787375726882]\n",
      "0.001\n",
      "[[28427     5]\n",
      " [    9    21]]\n",
      "epoch :[3] train loss [0.030825096879973004] val score [0.8748769079271295]\n",
      "0.001\n",
      "[[28429     3]\n",
      " [   23     7]]\n",
      "epoch :[4] train loss [0.03181507224592927] val score [0.6747714647352507]\n",
      "0.001\n",
      "[[28427     5]\n",
      " [   11    19]]\n",
      "epoch :[5] train loss [0.032181891383010176] val score [0.851711180144449]\n",
      "0.001\n",
      "[[28427     5]\n",
      " [    8    22]]\n",
      "epoch :[6] train loss [0.03238923329809856] val score [0.8858506104888013]\n",
      "0.001\n",
      "[[28427     5]\n",
      " [    7    23]]\n",
      "epoch :[7] train loss [0.03294803378393565] val score [0.8964462129361583]\n",
      "0.001\n",
      "[[28428     4]\n",
      " [   11    19]]\n",
      "epoch :[8] train loss [0.03238526753446446] val score [0.8583586886309732]\n",
      "0.001\n",
      "[[28430     2]\n",
      " [   24     6]]\n",
      "epoch :[9] train loss [0.03188092860439166] val score [0.6576662096122069]\n",
      "0.001\n",
      "[[28427     5]\n",
      " [    7    23]]\n",
      "epoch :[10] train loss [0.032123489981943185] val score [0.8964462129361583]\n",
      "0.001\n",
      "[[28431     1]\n",
      " [   23     7]]\n",
      "epoch :[11] train loss [0.031911555427072295] val score [0.6839995781035756]\n",
      "0.001\n",
      "[[28429     3]\n",
      " [   13    17]]\n",
      "epoch :[12] train loss [0.032062063386221105] val score [0.8398593381861659]\n",
      "0.001\n",
      "[[28429     3]\n",
      " [   10    20]]\n",
      "epoch :[13] train loss [0.031776159742822024] val score [0.8772441968135101]\n",
      "0.001\n",
      "[[28427     5]\n",
      " [    9    21]]\n",
      "epoch :[14] train loss [0.03159229556775146] val score [0.8748769079271295]\n",
      "0.001\n",
      "[[28427     5]\n",
      " [   10    20]]\n",
      "epoch :[15] train loss [0.03164225030740547] val score [0.8635044815916644]\n",
      "0.001\n",
      "[[28427     5]\n",
      " [   11    19]]\n",
      "epoch :[16] train loss [0.031464430382433496] val score [0.851711180144449]\n",
      "0.001\n",
      "[[28427     5]\n",
      " [    9    21]]\n",
      "epoch :[17] train loss [0.03170389507483741] val score [0.8748769079271295]\n",
      "0.001\n",
      "[[28427     5]\n",
      " [    9    21]]\n",
      "epoch :[18] train loss [0.031621037067786996] val score [0.8748769079271295]\n",
      "0.001\n",
      "[[28430     2]\n",
      " [   23     7]]\n",
      "epoch :[19] train loss [0.03142532536701504] val score [0.6792674379032821]\n",
      "0.001\n",
      "[[28428     4]\n",
      " [   13    17]]\n",
      "epoch :[20] train loss [0.031099749520220564] val score [0.833183877528294]\n",
      "0.001\n",
      "[[28427     5]\n",
      " [   11    19]]\n",
      "epoch :[21] train loss [0.030998798596752065] val score [0.851711180144449]\n",
      "0.001\n",
      "[[28429     3]\n",
      " [   22     8]]\n",
      "epoch :[22] train loss [0.031040238801206176] val score [0.694902201909525]\n",
      "0.001\n",
      "[[28430     2]\n",
      " [   20    10]]\n",
      "epoch :[23] train loss [0.03091800972952971] val score [0.7379018553027905]\n",
      "0.001\n",
      "[[28427     5]\n",
      " [    8    22]]\n",
      "epoch :[24] train loss [0.03128663245839121] val score [0.8858506104888013]\n",
      "0.001\n",
      "[[28429     3]\n",
      " [   11    19]]\n",
      "epoch :[25] train loss [0.031284002202976446] val score [0.8652615319692264]\n",
      "0.001\n",
      "[[28428     4]\n",
      " [   11    19]]\n",
      "epoch :[26] train loss [0.031192324454207058] val score [0.8583586886309732]\n",
      "0.001\n",
      "[[28427     5]\n",
      " [    9    21]]\n",
      "epoch :[27] train loss [0.03102772927638394] val score [0.8748769079271295]\n",
      "0.001\n",
      "[[28431     1]\n",
      " [   27     3]]\n",
      "epoch :[28] train loss [0.031010114867657822] val score [0.5879892051740717]\n",
      "0.001\n",
      "[[28429     3]\n",
      " [   12    18]]\n",
      "epoch :[29] train loss [0.03098724700610734] val score [0.8528093037014359]\n",
      "0.001\n",
      "[[28427     5]\n",
      " [    9    21]]\n",
      "epoch :[30] train loss [0.030914665036939185] val score [0.8748769079271295]\n",
      "0.001\n",
      "[[28428     4]\n",
      " [   13    17]]\n",
      "epoch :[31] train loss [0.030816600119252375] val score [0.833183877528294]\n",
      "0.001\n",
      "[[28431     1]\n",
      " [   20    10]]\n",
      "epoch :[32] train loss [0.03068403859576837] val score [0.7437178496040009]\n",
      "0.001\n",
      "[[28430     2]\n",
      " [   16    14]]\n",
      "epoch :[33] train loss [0.03072401948039307] val score [0.8041895926750926]\n",
      "0.001\n",
      "[[28430     2]\n",
      " [   28     2]]\n",
      "epoch :[34] train loss [0.03060559155795339] val score [0.5585598626865054]\n",
      "0.001\n",
      "[[28429     3]\n",
      " [   12    18]]\n",
      "epoch :[35] train loss [0.030843240162984138] val score [0.8528093037014359]\n",
      "0.001\n",
      "[[28431     1]\n",
      " [   25     5]]\n",
      "epoch :[36] train loss [0.0306484899045106] val score [0.6386603696932764]\n",
      "0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c3a528-b82e-4abd-8bb8-a77aa77bb6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score, pred_y, true_y = trainer.validation(trainer.model, 0.93)\n",
    "f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774b3c8f-1aec-48c0-9f5f-2de0772337f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = np.where(np.array(true_y) != np.array(pred_y))[0]\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4105eeb3-b7fd-4de2-91d7-28d327d17b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = trainer.predict(trainer.model, 0.93)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b897dc-6205-43a3-bf83-73d6f8d47d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('../dataset/sample_submission.csv')\n",
    "submit['Class'] = pred_y\n",
    "submit.to_csv('./submit_AE_embeding3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8308878f-f08b-4d44-9b59-fb6640310b26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0964ee7d-1b8e-438b-ba28-daae805450f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcca9e7-cdfc-46ca-9df0-81941a9cc5a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fe6b3d-38e8-47a9-890c-933db4c5d743",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2ad2fe-7f3b-4859-95ac-7a01ef8d8e32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c372c4e5-9777-4af1-874f-b2f1e9239355",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
